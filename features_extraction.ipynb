{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def add_features_to_dialogs_raw(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        dialogs = json.load(f)\n",
    "        \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        current_ind_both = 1\n",
    "\n",
    "        thread = dialog['thread']\n",
    "        for row in thread:\n",
    "            text = row['text']\n",
    "            # DO CLASSIFICATION HERE\n",
    "            # dialog_act, probability = predict_dialogue_act(text)\n",
    "            # row['dialogue_act'] = {'name': dialog_act, 'probability': probability}                        \n",
    "    with open(json_path + '.out', 'w') as f:\n",
    "        json.dump(dialogs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "add_features_to_dialogs_raw('f1-labeled-dialogs-with-dm.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features_dict(doc):\n",
    "    # Lemma: The base form of the word.\n",
    "    # POS: The simple UPOS part-of-speech tag.\n",
    "    # Tag: The detailed part-of-speech tag.\n",
    "    # Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "    # Shape: The word shape â€“ capitalization, punctuation, digits.\n",
    "    # is alpha: Is the token an alpha character?\n",
    "    # is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "    features = []\n",
    "    for token in doc:\n",
    "        features.append(\n",
    "            {\n",
    "                'lemma': token.lemma_, \n",
    "                 'pos': token.pos_, \n",
    "                 'tag': token.tag_, \n",
    "                 'dep': token.dep_,\n",
    "                 'shape': token.shape_, \n",
    "                 'is_alpha': token.is_alpha, \n",
    "                 'is_stop': token.is_stop\n",
    "            }\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def add_spacy_features_to_dialogs(json_path, nlp):\n",
    "    with open(json_path, 'r') as f:\n",
    "        dialogs = json.load(f)\n",
    "        \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        current_ind_both = 1\n",
    "\n",
    "        thread = dialog['thread']\n",
    "        for row in thread:\n",
    "            text = row['text']\n",
    "            doc = nlp(text)\n",
    "            features_dict = make_features_dict(doc)\n",
    "            row['features_dict'] = features_dict\n",
    "    return dialogs\n",
    "#     with open(json_path + '.out', 'w') as f:\n",
    "#         json.dump(dialogs, f, ensure_ascii=False, indent=2)\n",
    "#     return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "def load_sklearn_model(sgd_path, le_path, tfidf_path):\n",
    "    clf = joblib.load(sgd_path)\n",
    "    le = joblib.load(le_path)\n",
    "    tfidf = joblib.load(tfidf_path)\n",
    "    return clf, le, tfidf\n",
    "\n",
    "\n",
    "def add_discourse_features_to_dialogs_raw(dialogs, key, clf, le, tfidf):        \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        current_ind_both = 1\n",
    "\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            text = row['text']\n",
    "            if key == 'pair_discourse_type':\n",
    "                if ind > 0:\n",
    "                    prev_text = thread[ind - 1]['text']\n",
    "                    x = prev_text + ' . ' + text\n",
    "                    x = tfidf.transform([x])\n",
    "                    pair_label = clf.predict(x)\n",
    "                    pair_label = le.inverse_transform(pair_label)\n",
    "                    row[key] = pair_label[0]\n",
    "            elif key == 'single_discourse_type':\n",
    "                x = text\n",
    "                x = tfidf.transform([x])\n",
    "                single_label = clf.predict(x)\n",
    "                single_label = le.inverse_transform(single_label)\n",
    "                row[key] = single_label[0]\n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "clf_pair, le_pair, tfidf_pair = load_sklearn_model('pairs/discofuse_sgd_pairs.joblib', 'pairs/discofuse_le_pairs.joblib', 'pairs/discofuse_tfidf_pairs.joblib')\n",
    "clf_single, le_single, tfidf_single = load_sklearn_model('single/discofuse_sgd_single.joblib', 'single/discofuse_le_single.joblib', 'single/discofuse_tfidf_single.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/multi-woz2-dima.json'\n",
    "out_fname = 'data/multi-woz2.spacy.dialogact.discourse.2909.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_with_spacy = add_spacy_features_to_dialogs(fname, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_with_discourse_pairs = add_discourse_features_to_dialogs_raw(dialogs_with_spacy, 'pair_discourse_type', clf_pair, le_pair, tfidf_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_with_discourse_single = add_discourse_features_to_dialogs_raw(dialogs_with_discourse_pairs, 'single_discourse_type', clf_single, le_single, tfidf_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_fname, 'w') as f:\n",
    "    json.dump(dialogs_with_discourse_single, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
