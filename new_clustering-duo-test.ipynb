{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_key = 'multi-woz2'\n",
    "# output_key = 'topicalchat'\n",
    "# input_json = 'data/multi-woz2.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "# input_json = 'data/convai1.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "# input_json = 'data/convai2.spacy.dialogact.discourse.dialogtagger.0110.json'\n",
    "# input_json = 'data/multi-woz2.spacy.dialogact.discourse.dialogtagger.0110.json'\n",
    "\n",
    "n = 1\n",
    "\n",
    "features_name = 'dialog_tagger_features'\n",
    "# features_name = 'discourse_features'\n",
    "# features_name = 'topic_model_features'\n",
    "if output_key == 'multi-woz2':\n",
    "    input_json = f'data/{output_key}.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "    min_thresh = 0.74 # dialog_tagger_features, n=4, n=2, n=1 (top-10 99% of data) (topic model n4 Threshold: 0.7. Original clusters: 11043. After merging: 1006. \n",
    "                                                                                 # Top-10 clusters covers 28.999999999999996% of data, top-25 48.0%, top-50 61.0% )\n",
    "    if features_name == 'topic_model_features' and n == 1:\n",
    "        min_thresh = 0.64\n",
    "#     min_thresh = 0.6 # for topic model\n",
    "elif output_key == 'topicalchat':\n",
    "    input_json = f'data/{output_key}.train.spacy.dialogact.discourse.topicmodel.0310.json'\n",
    "    if features_name == 'dialog_tagger_features':\n",
    "        min_thresh = 0.65 \n",
    "    if features_name == 'discourse_features':\n",
    "        min_thresh = 0.7 \n",
    "    if features_name == 'topic_model_features':\n",
    "        min_thresh = 0.64\n",
    "\n",
    "\n",
    "\n",
    "output_folder = f'data/results/{output_key}_{n}_{features_name}/'\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "data_path = output_folder + 'data.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_json, 'r') as f:\n",
    "    dialogs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(dialog['thread']) for dialog_id, dialog in dialogs.items()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(utterance):\n",
    "    dialog_act_features = [p[0] for p in utterance.get('predictions', utterance.get('cobot_predictions')) if '_dci' in p[0]]\n",
    "    pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "    single_discourse_type = utterance['single_discourse_type']\n",
    "    pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "#     dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "    dialog_tagger_features = [f\"{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "    if dialog_tagger_features:\n",
    "        dialog_tagger_features = [dialog_tagger_features[0]]\n",
    "    else:\n",
    "        dialog_tagger_features = ['Undetected']\n",
    "    topic_model_features = [f[0] for f in utterance['topic_model_features']]\n",
    "    \n",
    "    if features_name == 'dialog_tagger_features':\n",
    "        features = dialog_tagger_features\n",
    "    elif features_name == 'discourse_features':\n",
    "        features = [single_discourse_type]\n",
    "        if pair_discourse_type and pair_discourse_type != 'PAIR_NONE':\n",
    "            features += [pair_discourse_type]\n",
    "    elif features_name == 'topic_model_features':\n",
    "        features = topic_model_features\n",
    "    else:\n",
    "        raise ArgumentError()\n",
    "        features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] + topic_model_features  #+ [pos_features]    \n",
    "        if pair_discourse_type and pair_discourse_type != 'PAIR_NONE':\n",
    "            features += [pair_discourse_type]\n",
    "#     features = dialog_tagger_features + [pair_discourse_type] + [single_discourse_type]\n",
    "#     features = dialog_act_features + dialog_tagger_features\n",
    "    return features\n",
    "\n",
    "def get_thread_key(n):    \n",
    "    key = f'thread{n}'\n",
    "    return key\n",
    "\n",
    "# def get_thread_key(n):\n",
    "#     if n == 1:\n",
    "#         key = 'thread'\n",
    "#     else:\n",
    "#         key = f'thread{n}'\n",
    "#     return key\n",
    "\n",
    "# def get_features(utterance):\n",
    "#     dialog_act_features = [p[0] for p in utterance['predictions']]\n",
    "#     pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "#     single_discourse_type = utterance['single_discourse_type']\n",
    "#     pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "#     dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "\n",
    "#     features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] + [pos_features]\n",
    "#     if pair_discourse_type:\n",
    "#         features += [pair_discourse_type]\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_id, dialog in dialogs.items():\n",
    "    thread = dialog['thread']\n",
    "    for ind, row in enumerate(thread):\n",
    "        features = get_features(row)\n",
    "#         features = [f\"{ind}_{e}\" for e in features]\n",
    "        row['final_features'] = frozenset(features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_clusters(dialogs):\n",
    "    clusters = set()\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            clusters.add(row['final_features'])\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_n_cluster(dialogs, n):\n",
    "    clusters = set()    \n",
    "    thread_key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        n_thread = []\n",
    "        for ind, row in enumerate(thread):\n",
    "            if ind > n - 2:\n",
    "                new_row = {}\n",
    "                new_cluster = frozenset()\n",
    "                prev_texts = []\n",
    "                for j in range(0, n):\n",
    "                    prev_row = thread[ind - j]\n",
    "                    feats = copy.deepcopy(prev_row['final_features'])\n",
    "                    feats = frozenset([f\"{f}\" for f in feats])\n",
    "                    new_cluster = frozenset.union(new_cluster, feats)\n",
    "                    prev_texts.append(prev_row['text'])\n",
    "                new_row['final_features'] = new_cluster                \n",
    "                prev_texts.reverse()\n",
    "                for j, text in enumerate(prev_texts):\n",
    "                    new_row[f'text{j}'] = text\n",
    "                clusters.add(new_cluster)\n",
    "                n_thread.append(new_row)\n",
    "        if n_thread:\n",
    "            dialog[thread_key] = n_thread\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    at_least_one_with_thread_key = False\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if thread_key not in dialog:\n",
    "            continue\n",
    "        else:\n",
    "            at_least_one_with_thread_key = True\n",
    "        thread = dialog[thread_key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    assert at_least_one_with_thread_key\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    res = round(len(s1.intersection(s2)) / len(s1.union(s2)), 5)\n",
    "    if res < 0:\n",
    "        res = 0\n",
    "    if res > 1:\n",
    "        res = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = collect_n_cluster(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims_info(clusters, for_hist=False):\n",
    "    used_inds = set()\n",
    "    sims_info = []\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])}            \n",
    "    for i in range(len(clusters)):\n",
    "        max_sim = 0\n",
    "        max_ind = 0\n",
    "        for j in range(i+1, len(clusters)):        \n",
    "            cur_sim = jaccard_similarity(reverse_index[i], reverse_index[j])\n",
    "            if max_sim <= cur_sim:\n",
    "                max_sim = cur_sim\n",
    "                max_ind = j   \n",
    "        if (i not in used_inds) and (max_ind not in used_inds) and not for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "            used_inds.add(i)\n",
    "            used_inds.add(max_ind)\n",
    "        elif for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "    return sims_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_info = get_sims_info(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Между уникальными кластерами\n",
    "sims_info_for_hist = get_sims_info(clusters, True)\n",
    "fig = px.histogram(sims_info_for_hist, x=\"sim\", nbins=len(sims_info_for_hist))\n",
    "fig.write_html(output_folder + 'sims_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sims_and_merge_clusters(sims_info, clusters, threshold, dialogs, n):\n",
    "    new_clusters = {}\n",
    "    cluster_id = 0\n",
    "    used_inds = []\n",
    "    is_merged = False\n",
    "    cluster_id_mapping = {}\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])} \n",
    "    for e in sims_info:\n",
    "        if e['sim'] >= threshold:\n",
    "            new_cluster = frozenset().union(reverse_index[e['source_ind']], reverse_index[e['target_ind']])\n",
    "            if new_cluster not in new_clusters:                \n",
    "                new_clusters[new_cluster] = cluster_id\n",
    "                cluster_id += 1\n",
    "                is_merged = True\n",
    "            used_inds += [e['source_ind'], e['target_ind']]\n",
    "            cluster_id_mapping[e['source_ind']] = new_clusters[new_cluster]\n",
    "            cluster_id_mapping[e['target_ind']] = new_clusters[new_cluster]\n",
    "    used_inds = set(used_inds)\n",
    "    for ind in reverse_index.keys():\n",
    "        if ind not in used_inds:\n",
    "            if reverse_index[ind] not in new_clusters:                \n",
    "                new_clusters[reverse_index[ind]] = cluster_id\n",
    "                cluster_id += 1\n",
    "            cluster_id_mapping[ind] = new_clusters[reverse_index[ind]]    \n",
    "    if is_merged is True:\n",
    "        at_least_one_with_thread_key = False\n",
    "        for dialog_id, dialog in dialogs.items():\n",
    "            key = get_thread_key(n)            \n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            else:\n",
    "                at_least_one_with_thread_key = True\n",
    "                thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):\n",
    "                row['cluster_id'] = cluster_id_mapping[row['cluster_id']]\n",
    "        assert at_least_one_with_thread_key\n",
    "        return filter_sims_and_merge_clusters(get_sims_info(new_clusters), new_clusters, threshold, dialogs, n)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = filter_sims_and_merge_clusters(sims_info, clusters, min_thresh, dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(new_clusters, dialogs, n=1):\n",
    "    cluster_ids = set()\n",
    "    key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_ids.add(row['cluster_id'])\n",
    "    assert len(cluster_ids) == len(new_clusters), print(len(cluster_ids), len(new_clusters))\n",
    "\n",
    "check_correctness(new_clusters, dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump new_clusters, old_clusters, dialogs, n, min_thresh, graphs\n",
    "\n",
    "def dump_data(n):\n",
    "    compressed_dialogs = {}\n",
    "    key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        compressed_thread = []\n",
    "        for ind, row in enumerate(thread):            \n",
    "            compressed_row = {'cluster_id': row['cluster_id']}\n",
    "            for i in range(n):\n",
    "                compressed_row[f'text{i}'] = row[f'text{i}']\n",
    "            compressed_thread.append(compressed_row)\n",
    "        compressed_dialogs[dialog_id] = {'thread': compressed_thread}\n",
    "    \n",
    "    res = joblib.dump(\n",
    "        {'new_clusters': new_clusters, 'clusters': clusters, 'n': n, 'min_thresh': min_thresh, 'dialog': compressed_dialogs},\n",
    "        data_path, \n",
    "    )\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    data = joblib.load(data_path)\n",
    "    return data\n",
    "\n",
    "dump_data(n)\n",
    "# data = load_data()\n",
    "# dialogs = data['dialogs']\n",
    "# new_clusters = data['new_clusters']\n",
    "# clusters = data['clusters']\n",
    "# n = data['n']\n",
    "# min_thresh = data['min_thresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index = {i: c for c, i in sorted(new_clusters.items(), key=lambda x: x[1])} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cluster_cluster_usage_distribution(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    cluster_usage_distribution = defaultdict(int)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_usage_distribution[row['cluster_id']] += 1\n",
    "    return cluster_usage_distribution\n",
    "\n",
    "cluster_usage_distribution = calc_cluster_cluster_usage_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [f\"c_{e}\" for e in list(cluster_usage_distribution.keys())]\n",
    "fig = px.histogram(x=xs, y=list(cluster_usage_distribution.values()), nbins=len(cluster_usage_distribution.keys()), labels={'x': 'cluster id'})\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.write_html(output_folder + 'usage_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_examples(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    cluster_examples = defaultdict(list)    \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):                \n",
    "                prev_texts = []\n",
    "                for i in range(0, n):\n",
    "                    text_key = f'text{i}'\n",
    "                    prev_texts.append(row[text_key])\n",
    "                cluster_examples[row['cluster_id']].append(prev_texts)\n",
    "    return cluster_examples\n",
    "\n",
    "cluster_examples = get_cluster_examples(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_features(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    orig_features = defaultdict(list)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):          \n",
    "                orig_features[row['cluster_id']].append(row['final_features'])\n",
    "    return orig_features\n",
    "\n",
    "orig_features = get_original_features(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_by_turns_distribution(dialogs, n):\n",
    "    # { Cluster_id: {turn_num: count, ...}, ... }\n",
    "    key = get_thread_key(n)\n",
    "    cluster_turns_distr = defaultdict(dict)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):     \n",
    "            if ind not in cluster_turns_distr[row['cluster_id']]:\n",
    "                cluster_turns_distr[row['cluster_id']][ind] = 1\n",
    "            else:\n",
    "                cluster_turns_distr[row['cluster_id']][ind] += 1\n",
    "    return cluster_turns_distr\n",
    "cluster_turns_distr = get_cluster_by_turns_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_features_distribution(dialogs, n):\n",
    "    # {feature: [cluster_id1, cluster_id2, ...]}\n",
    "    key = get_thread_key(n)\n",
    "    features_distr = defaultdict(int)\n",
    "#     features_distr = defaultdict(set)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):  \n",
    "            for feature in row['final_features']:\n",
    "                features_distr[feature] += 1\n",
    "#                 features_distr[feature].add(row['cluster_id'])            \n",
    "    return features_distr\n",
    "features_distr = get_cluster_features_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_confidence(feature, cluster_id, features_distr, cluster_examples):    \n",
    "    final_cluster_size = len(cluster_examples[cluster_id])\n",
    "    features_before_clustering = orig_features[cluster_id]\n",
    "    n = 0\n",
    "    for fs in features_before_clustering:\n",
    "        if feature in fs:\n",
    "            n += 1\n",
    "    return round(n / final_cluster_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.8, 5.24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mean_and_std_turn(cluster_turns_distr, cluster_id):\n",
    "    arr = []\n",
    "    for turn_num, count in cluster_turns_distr[cluster_id].items():\n",
    "        arr += [turn_num]*count\n",
    "    arr = np.array(arr)\n",
    "    return round(np.mean(arr), 1), round(np.std(arr), 2)\n",
    "\n",
    "get_mean_and_std_turn(cluster_turns_distr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coverage(top_k):\n",
    "    coverage = sum([freq for cluster_id, freq in sorted(cluster_usage_distribution.items(), key=lambda x: x[1], reverse=True)[:top_k]]) / sum(cluster_usage_distribution.values())\n",
    "    return round(coverage, 2)*100\n",
    "top_k = 10\n",
    "result_report = \"Help:\\n\"\n",
    "result_report += \"- Turn dist calculated as: Turn X freq / Frequency \\n\"\n",
    "result_report += \"- Feature confidence calculated as: min(1, number_of_clusters_that_has_this_feature / original total feature freq) \\n\"\n",
    "result_report += \"\\n\"\n",
    "result_report += f\"Threshold: {min_thresh}. Original clusters: {len(clusters)}. After merging: {len(new_clusters)}. \\n\"\n",
    "result_report += f\"Top-{top_k} clusters covers {calc_coverage(top_k)}% of data, top-25 {calc_coverage(25)}%, top-50 {calc_coverage(50)}% \\n\"\n",
    "result_report += \"\\n\"\n",
    "top_cluster_ids = []\n",
    "for cluster_id, freq in sorted(cluster_usage_distribution.items(), key=lambda x: x[1], reverse=True)[:top_k]:\n",
    "    if freq < 2:\n",
    "        continue\n",
    "    total_turns_count = len(cluster_turns_distr[cluster_id].values())    \n",
    "    result_report += f\"Cluster id: {cluster_id}; Frequency: {freq}; Present in {total_turns_count} turns.\\n \"\n",
    "    sorted_cluster_turns_distr = sorted(cluster_turns_distr[cluster_id].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    top_turns_count = [f\"Turn {turn_num} freq: {count}, dist: {round(count / freq, 2)}\" for turn_num, count in sorted_cluster_turns_distr]\n",
    "    mean_turn, std_turn = get_mean_and_std_turn(cluster_turns_distr, cluster_id)\n",
    "    result_report += f\"Mean turn: {mean_turn} +- {std_turn} \\n\"\n",
    "    result_report += \"Top 3 freq turns: \\n\"\n",
    "    for turn_num, count in sorted_cluster_turns_distr:\n",
    "        result_report += f\" - Turn {turn_num} freq: {count}, dist: {round(count / freq, 2)}\\n\"        \n",
    "    result_report += \"-------------\\n\"\n",
    "    for feature in sorted(reverse_index[cluster_id], key=lambda x: x[0]):        \n",
    "        result_report += f\"{feature}: {calc_feature_confidence(feature, cluster_id, features_distr, cluster_examples)}. \"\n",
    "        result_report += f'Orig freq: {features_distr[feature]}\\n'\n",
    "    result_report += \"Samples: \\n\"\n",
    "    for example_sentences in random.sample(cluster_examples[cluster_id], min(10, len(cluster_examples[cluster_id]))):\n",
    "        result_report += \"- \\n\"\n",
    "        for i, s in enumerate(example_sentences):        \n",
    "            result_report += f\"-- S{i}: {s} \\n\"        \n",
    "    result_report += \"-------------\\n\"\n",
    "    result_report += \"\\n\"\n",
    "    top_cluster_ids.append(cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SNG01856.json', 'SNG0129.json', 'PMUL1635.json']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dialogs.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in dialogs['PMUL1635.json']['thread1']:\n",
    "#     print(reverse_index[row['cluster_id']], row['cluster_id'])\n",
    "#     print('S0 ', row['text0'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help:\n",
      "- Turn dist calculated as: Turn X freq / Frequency \n",
      "- Feature confidence calculated as: min(1, number_of_clusters_that_has_this_feature / original total feature freq) \n",
      "\n",
      "Threshold: 0.74. Original clusters: 11. After merging: 11. \n",
      "Top-10 clusters covers 100.0% of data, top-25 100.0%, top-50 100.0% \n",
      "\n",
      "Cluster id: 8; Frequency: 85923; Present in 41 turns.\n",
      " Mean turn: 6.6 +- 5.11 \n",
      "Top 3 freq turns: \n",
      " - Turn 3 freq: 7835, dist: 0.09\n",
      " - Turn 0 freq: 7335, dist: 0.09\n",
      " - Turn 1 freq: 7332, dist: 0.09\n",
      "-------------\n",
      "Statement: 1.0. Orig freq: 85923\n",
      "Samples: \n",
      "- \n",
      "-- S0: I need 4 tickets. What is the reference number? \n",
      "- \n",
      "-- S0: depart from birmingham new street ,I want to leave on Friday and arrive by 14:30 \n",
      "- \n",
      "-- S0: I've found the All Saint's Church which is at Jesus Lane.  There is no entrance fee.  Would you like further information? \n",
      "- \n",
      "-- S0: Does it have a 4 star rating? \n",
      "- \n",
      "-- S0: The postcode is cb13js.  Would you like to get a room reserved? \n",
      "- \n",
      "-- S0: The Cambridge artworks museum is located at 5 greens road cb13ef. It has free admission.  \n",
      "- \n",
      "-- S0: I will be commuting between the hotel and restaurant. \n",
      "- \n",
      "-- S0: I have a name of a hotel that I'm looking to book. \n",
      "- \n",
      "-- S0: Whatever hotel you booked me at. The reference number is: GXQZCBL8  \n",
      "- \n",
      "-- S0: I have several options would you like the info? \n",
      "-------------\n",
      "\n",
      "Cluster id: 3; Frequency: 24321; Present in 37 turns.\n",
      " Mean turn: 6.4 +- 5.2 \n",
      "Top 3 freq turns: \n",
      " - Turn 1 freq: 2456, dist: 0.1\n",
      " - Turn 0 freq: 2405, dist: 0.1\n",
      " - Turn 2 freq: 2276, dist: 0.09\n",
      "-------------\n",
      "Directive: 1.0. Orig freq: 24321\n",
      "Samples: \n",
      "- \n",
      "-- S0: Please give me the phone number. \n",
      "- \n",
      "-- S0: Could you please be kind enough and get me information on the autumn house? \n",
      "- \n",
      "-- S0: I'd like to find a Turkish restaurant in the center of town. \n",
      "- \n",
      "-- S0: Can you book tickets for 4 people please? \n",
      "- \n",
      "-- S0: I'd like to leave on Monday and arrive by 18:00. \n",
      "- \n",
      "-- S0: Can we go ahead and book that for 5 people for 3 nights starting on Saturday? \n",
      "- \n",
      "-- S0: I would suggest booking TR9724 \n",
      "- \n",
      "-- S0: I'm exhausted. Can you find me a guesthouse somewhere on the east side of town? \n",
      "- \n",
      "-- S0: Great! Can you also help me find a modern european restaurant in the south? \n",
      "- \n",
      "-- S0: We have several choices. Do you have a preference in the type of food? \n",
      "-------------\n",
      "\n",
      "Cluster id: 9; Frequency: 16137; Present in 41 turns.\n",
      " Mean turn: 11.4 +- 5.35 \n",
      "Top 3 freq turns: \n",
      " - Turn 12 freq: 1659, dist: 0.1\n",
      " - Turn 14 freq: 1534, dist: 0.1\n",
      " - Turn 6 freq: 1488, dist: 0.09\n",
      "-------------\n",
      "Thanking: 1.0. Orig freq: 16137\n",
      "Samples: \n",
      "- \n",
      "-- S0: You are great thanks ! \n",
      "- \n",
      "-- S0: Perfect! That's all I needed, thank you for your help. \n",
      "- \n",
      "-- S0: You're very welcome!  I hope that you enjoy your time here!  Thank you for contacting Cambridge TownInfo centre. \n",
      "- \n",
      "-- S0: You're more than welcome! \n",
      "- \n",
      "-- S0: You are very welcome.  I hope you enjoy your trip. \n",
      "- \n",
      "-- S0: Thank you very much! \n",
      "- \n",
      "-- S0: Yes, I in am interested in an expensive restaurant. Thanks!  \n",
      "- \n",
      "-- S0: Yes it is, thanks for your assistance. \n",
      "- \n",
      "-- S0: Nothing else, thank you lots. \n",
      "- \n",
      "-- S0: Thank you for your help. Have a great evening. \n",
      "-------------\n",
      "\n",
      "Cluster id: 1; Frequency: 6779; Present in 36 turns.\n",
      " Mean turn: 7.6 +- 5.04 \n",
      "Top 3 freq turns: \n",
      " - Turn 4 freq: 701, dist: 0.1\n",
      " - Turn 5 freq: 599, dist: 0.09\n",
      " - Turn 2 freq: 593, dist: 0.09\n",
      "-------------\n",
      "CheckQ: 1.0. Orig freq: 6779\n",
      "Samples: \n",
      "- \n",
      "-- S0: Can you book tickets for me? \n",
      "- \n",
      "-- S0: Yes, please give me the phone number. \n",
      "- \n",
      "-- S0: Could you just give me the number for pizza express.  \n",
      "- \n",
      "-- S0: Yes please book a table for 7 people at 16:45 on Sunday.  Can you give me the reference number? \n",
      "- \n",
      "-- S0: Can you give me the postcode for that hotel? \n",
      "- \n",
      "-- S0: Is there anything else I can help you with, such as finding a restaurant or an attraction? \n",
      "- \n",
      "-- S0: Your booking was successful. The reference number is : PWSAA94F. Is there anything else I can help you with? \n",
      "- \n",
      "-- S0: Great! Can you tell me the area of town that's located in, and give me their phone number, please? \n",
      "- \n",
      "-- S0: Yes, may I please have their address and phone number.  \n",
      "- \n",
      "-- S0: The phone number is 01223240089, and the post code is cb17sr. Is there anything else I can assist you with? \n",
      "-------------\n",
      "\n",
      "Cluster id: 10; Frequency: 3095; Present in 33 turns.\n",
      " Mean turn: 9.8 +- 5.68 \n",
      "Top 3 freq turns: \n",
      " - Turn 6 freq: 267, dist: 0.09\n",
      " - Turn 4 freq: 252, dist: 0.08\n",
      " - Turn 10 freq: 215, dist: 0.07\n",
      "-------------\n",
      "Undetected: 1.0. Orig freq: 3095\n",
      "Samples: \n",
      "- \n",
      "-- S0: I think that covers everything. Thanks for your assistance today, you've been so helpful! \n",
      "- \n",
      "-- S0: Have a wonderful day! \n",
      "- \n",
      "-- S0: Goodbye.  \n",
      "- \n",
      "-- S0: Ok! Have a great day! \n",
      "- \n",
      "-- S0: Yes, I don't want to leave for Cambridge until 15:00 at the earliest. \n",
      "- \n",
      "-- S0: yes please book it for me \n",
      "- \n",
      "-- S0: That sounds like it would work.  Please make a reservation for 4 people on that train, please. \n",
      "- \n",
      "-- S0: Ok, thank you. One more thing. What was the price of the train ticket? \n",
      "- \n",
      "-- S0: No problem, where to where, and when to when? \n",
      "- \n",
      "-- S0: In that case I hope you have a wonderful visit and enjoy the rest of your day! Goodbye! \n",
      "-------------\n",
      "\n",
      "Cluster id: 6; Frequency: 2908; Present in 32 turns.\n",
      " Mean turn: 10.3 +- 6.36 \n",
      "Top 3 freq turns: \n",
      " - Turn 0 freq: 347, dist: 0.12\n",
      " - Turn 15 freq: 284, dist: 0.1\n",
      " - Turn 13 freq: 264, dist: 0.09\n",
      "-------------\n",
      "Salutation: 1.0. Orig freq: 2908\n",
      "Samples: \n",
      "- \n",
      "-- S0: You're welcome.  \n",
      "- \n",
      "-- S0: Ok, hope you have a good day too. Bye. \n",
      "- \n",
      "-- S0: You are very welcome.  Good bye. \n",
      "- \n",
      "-- S0: You are welcome. Enjoy your stay. \n",
      "- \n",
      "-- S0: No. That's perfect! Thanks for your help. Good bye. \n",
      "- \n",
      "-- S0: Ok. Good luck with your dispute! Goodbye. \n",
      "- \n",
      "-- S0: I'm glad I could be of help today. Good-bye. \n",
      "- \n",
      "-- S0: You are welcome, enjoy your day. \n",
      "- \n",
      "-- S0: Hello! I need a guesthouse to stay in, and I really need it to include free parking for my van. Can you help? \n",
      "- \n",
      "-- S0: You are welcome enjoy \n",
      "-------------\n",
      "\n",
      "Cluster id: 4; Frequency: 1725; Present in 31 turns.\n",
      " Mean turn: 8.9 +- 5.63 \n",
      "Top 3 freq turns: \n",
      " - Turn 2 freq: 204, dist: 0.12\n",
      " - Turn 4 freq: 202, dist: 0.12\n",
      " - Turn 6 freq: 154, dist: 0.09\n",
      "-------------\n",
      "Feedback: 1.0. Orig freq: 1725\n",
      "Samples: \n",
      "- \n",
      "-- S0: Yes, please. That would be great. \n",
      "- \n",
      "-- S0: That sounds interesting, what type of attraction is it? \n",
      "- \n",
      "-- S0: 11:15 would be perfect.  \n",
      "- \n",
      "-- S0: yes it is \n",
      "- \n",
      "-- S0: That sounds wonderful! \n",
      "- \n",
      "-- S0: Yes, sometime after 09:15. \n",
      "- \n",
      "-- S0: I think a museums might be nice. Can you recommend one to me? \n",
      "- \n",
      "-- S0: Ok great.  Anything else you need?   \n",
      "- \n",
      "-- S0: Sure,a  museum sounds good, what do you have that's free? \n",
      "- \n",
      "-- S0: No, that looks good to me. You have a great day. \n",
      "-------------\n",
      "\n",
      "Cluster id: 2; Frequency: 1280; Present in 28 turns.\n",
      " Mean turn: 7.8 +- 5.24 \n",
      "Top 3 freq turns: \n",
      " - Turn 2 freq: 150, dist: 0.12\n",
      " - Turn 6 freq: 112, dist: 0.09\n",
      " - Turn 4 freq: 107, dist: 0.08\n",
      "-------------\n",
      "Commissive: 1.0. Orig freq: 1280\n",
      "Samples: \n",
      "- \n",
      "-- S0: I would like to leave the restaurant by 04:00. \n",
      "- \n",
      "-- S0: Departing from cambridge and I want to arrive somewhere around 20:00, can you get me 7 tickets and I'll need the reference number too. \n",
      "- \n",
      "-- S0: I will book that for you now. \n",
      "- \n",
      "-- S0: Can I do anything else for you today? \n",
      "- \n",
      "-- S0: I'll check that out. Can you also find me a train for Monday I'm leaving leicester?  \n",
      "- \n",
      "-- S0: I'll be heading to Peterborough from Cambridge. \n",
      "- \n",
      "-- S0: Okay, let me know if and when I can book it for you.  \n",
      "- \n",
      "-- S0: I'll be leaving Cambridge on Thursday. \n",
      "- \n",
      "-- S0: I will go with the earlier departure, and I would like 2 seats please. I will also need a reference number. \n",
      "- \n",
      "-- S0: I can work on booking this for you. \n",
      "-------------\n",
      "\n",
      "Cluster id: 7; Frequency: 546; Present in 25 turns.\n",
      " Mean turn: 5.4 +- 4.97 \n",
      "Top 3 freq turns: \n",
      " - Turn 1 freq: 186, dist: 0.34\n",
      " - Turn 7 freq: 50, dist: 0.09\n",
      " - Turn 5 freq: 44, dist: 0.08\n",
      "-------------\n",
      "SetQ: 1.0. Orig freq: 546\n",
      "Samples: \n",
      "- \n",
      "-- S0: And where are you leaving from? \n",
      "- \n",
      "-- S0: Anything in the west will do. What's your favorite? \n",
      "- \n",
      "-- S0: What time do you want to depart by and where from?  \n",
      "- \n",
      "-- S0: Yes, what type of attraction is it and what is the postcode? \n",
      "- \n",
      "-- S0: Where are you departing from?  \n",
      "- \n",
      "-- S0: Where are you leaving from and where are you going to? \n",
      "- \n",
      "-- S0: Where will you be departing and what is your destination? \n",
      "- \n",
      "-- S0: When does it arrive and what is the train ID? \n",
      "- \n",
      "-- S0: Okay. I can help you find a restaurant or hotel, look for tourist information, book a train or taxi. How may I help you ? \n",
      "- \n",
      "-- S0: OK, what is your departure station and what day are you traveling? \n",
      "-------------\n",
      "\n",
      "Cluster id: 0; Frequency: 331; Present in 29 turns.\n",
      " Mean turn: 9.1 +- 6.37 \n",
      "Top 3 freq turns: \n",
      " - Turn 5 freq: 36, dist: 0.11\n",
      " - Turn 1 freq: 30, dist: 0.09\n",
      " - Turn 3 freq: 26, dist: 0.08\n",
      "-------------\n",
      "Apology: 1.0. Orig freq: 331\n",
      "Samples: \n",
      "- \n",
      "-- S0: I'm sorry.  Yes, train TR1575 will arrive in Cambridge by 16:54. It leaves Leicester at 15:09.  Can I book it for you? \n",
      "- \n",
      "-- S0: I'm sorry not hotels, guesthouses please. \n",
      "- \n",
      "-- S0: Sorry about that. Worth House is a cheap guesthouse located in the north.  \n",
      "- \n",
      "-- S0: I have 2 guesthouses, when are you planning your stay, I am sorry \n",
      "- \n",
      "-- S0: I'm sorry, there are not guesthouses that meet your criteria.  There is 1 guesthouse that is 4 stars in the cheap price range in that area of town. \n",
      "- \n",
      "-- S0: no I am sorry no steakhouses, something else perhaps? \n",
      "- \n",
      "-- S0: No I am sorry. But there is a Portuguese restaurant if you are interested. \n",
      "- \n",
      "-- S0: Great, thanks, sorry for the confusion earlier! Can you help me find a train, too, please? I'm traveling from Bishops Stortford to Cambridge on the same day as my hotel reservation. \n",
      "- \n",
      "-- S0: Sorry.  I want to leave on Saturday after 20:30. \n",
      "- \n",
      "-- S0: Oh, sorry. 17:15 on Friday. \n",
      "-------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(output_folder + f'{output_key}_n-{n}_{features_name}_report.txt', 'w') as f:\n",
    "    print(result_report, file=f)\n",
    "print(result_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
