{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_key = 'multi-woz2'\n",
    "# output_key = 'topicalchat'\n",
    "# input_json = 'data/multi-woz2.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "# input_json = 'data/convai1.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "# input_json = 'data/convai2.spacy.dialogact.discourse.dialogtagger.0110.json'\n",
    "# input_json = 'data/multi-woz2.spacy.dialogact.discourse.dialogtagger.0110.json'\n",
    "\n",
    "features_name = 'dialog_tagger_features'\n",
    "# features_name = 'discourse_features'\n",
    "# features_name = 'topic_model_features'\n",
    "if output_key == 'multi-woz2':\n",
    "    input_json = f'data/{output_key}.spacy.dialogact.discourse.dialogtagger.topicmodel.0310.json'\n",
    "    min_thresh = 0.74 # dialog_tagger_features, n=4, n=2, n=1 (top-10 99% of data) (topic model n4 Threshold: 0.7. Original clusters: 11043. After merging: 1006. \n",
    "                                                                                 # Top-10 clusters covers 28.999999999999996% of data, top-25 48.0%, top-50 61.0% )\n",
    "#     min_thresh = 0.6 # for topic model\n",
    "elif output_key == 'topicalchat':\n",
    "    input_json = f'data/{output_key}.train.spacy.dialogact.discourse.topicmodel.0310.json'\n",
    "    if features_name == 'dialog_tagger_features':\n",
    "        min_thresh = 0.65 \n",
    "    if features_name == 'discourse_features':\n",
    "        min_thresh = 0.7 \n",
    "    if features_name == 'topic_model_features':\n",
    "        min_thresh = 0.64\n",
    "\n",
    "n = 1\n",
    "\n",
    "\n",
    "output_folder = f'data/results/{output_key}_{n}_{features_name}/'\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "data_path = output_folder + 'data.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_json, 'r') as f:\n",
    "    dialogs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(dialog['thread']) for dialog_id, dialog in dialogs.items()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(utterance):\n",
    "    dialog_act_features = [p[0] for p in utterance.get('predictions', utterance.get('cobot_predictions')) if '_dci' in p[0]]\n",
    "    pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "    single_discourse_type = utterance['single_discourse_type']\n",
    "    pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "    dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "    topic_model_features = [f[0] for f in utterance['topic_model_features']]\n",
    "    \n",
    "    if features_name == 'dialog_tagger_features':\n",
    "        features = dialog_tagger_features\n",
    "    elif features_name == 'discourse_features':\n",
    "        features = [single_discourse_type]\n",
    "        if pair_discourse_type and pair_discourse_type != 'PAIR_NONE':\n",
    "            features += [pair_discourse_type]\n",
    "    elif features_name == 'topic_model_features':\n",
    "        features = topic_model_features\n",
    "    else:\n",
    "        raise ArgumentError()\n",
    "        features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] + topic_model_features  #+ [pos_features]    \n",
    "        if pair_discourse_type and pair_discourse_type != 'PAIR_NONE':\n",
    "            features += [pair_discourse_type]\n",
    "#     features = dialog_tagger_features + [pair_discourse_type] + [single_discourse_type]\n",
    "#     features = dialog_act_features + dialog_tagger_features\n",
    "    return features\n",
    "\n",
    "def get_thread_key(n):    \n",
    "    key = f'thread{n}'\n",
    "    return key\n",
    "\n",
    "# def get_thread_key(n):\n",
    "#     if n == 1:\n",
    "#         key = 'thread'\n",
    "#     else:\n",
    "#         key = f'thread{n}'\n",
    "#     return key\n",
    "\n",
    "# def get_features(utterance):\n",
    "#     dialog_act_features = [p[0] for p in utterance['predictions']]\n",
    "#     pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "#     single_discourse_type = utterance['single_discourse_type']\n",
    "#     pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "#     dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "\n",
    "#     features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] + [pos_features]\n",
    "#     if pair_discourse_type:\n",
    "#         features += [pair_discourse_type]\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_id, dialog in dialogs.items():\n",
    "    thread = dialog['thread']\n",
    "    for ind, row in enumerate(thread):\n",
    "        features = get_features(row)\n",
    "#         features = [f\"{ind}_{e}\" for e in features]\n",
    "        row['final_features'] = frozenset(features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_clusters(dialogs):\n",
    "    clusters = set()\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            clusters.add(row['final_features'])\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_n_cluster(dialogs, n):\n",
    "    clusters = set()    \n",
    "    thread_key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        n_thread = []\n",
    "        for ind, row in enumerate(thread):\n",
    "            if ind > n - 2:\n",
    "                new_row = {}\n",
    "                new_cluster = frozenset()\n",
    "                prev_texts = []\n",
    "                for j in range(0, n):\n",
    "                    prev_row = thread[ind - j]\n",
    "                    feats = copy.deepcopy(prev_row['final_features'])\n",
    "                    feats = frozenset([f\"{n-j-1}_{f}\" for f in feats])\n",
    "                    new_cluster = frozenset.union(new_cluster, feats)\n",
    "                    prev_texts.append(prev_row['text'])\n",
    "                new_row['final_features'] = new_cluster                \n",
    "                prev_texts.reverse()\n",
    "                for j, text in enumerate(prev_texts):\n",
    "                    new_row[f'text{j}'] = text\n",
    "                clusters.add(new_cluster)\n",
    "                n_thread.append(new_row)\n",
    "        if n_thread:\n",
    "            dialog[thread_key] = n_thread\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    at_least_one_with_thread_key = False\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if thread_key not in dialog:\n",
    "            continue\n",
    "        else:\n",
    "            at_least_one_with_thread_key = True\n",
    "        thread = dialog[thread_key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    assert at_least_one_with_thread_key\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    res = round(len(s1.intersection(s2)) / len(s1.union(s2)), 5)\n",
    "    if res < 0:\n",
    "        res = 0\n",
    "    if res > 1:\n",
    "        res = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = collect_n_cluster(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims_info(clusters, for_hist=False):\n",
    "    used_inds = set()\n",
    "    sims_info = []\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])}            \n",
    "    for i in range(len(clusters)):\n",
    "        max_sim = 0\n",
    "        max_ind = 0\n",
    "        for j in range(i+1, len(clusters)):        \n",
    "            cur_sim = jaccard_similarity(reverse_index[i], reverse_index[j])\n",
    "            if max_sim <= cur_sim:\n",
    "                max_sim = cur_sim\n",
    "                max_ind = j   \n",
    "        if (i not in used_inds) and (max_ind not in used_inds) and not for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "            used_inds.add(i)\n",
    "            used_inds.add(max_ind)\n",
    "        elif for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "    return sims_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_info = get_sims_info(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Между уникальными кластерами\n",
    "sims_info_for_hist = get_sims_info(clusters, True)\n",
    "fig = px.histogram(sims_info_for_hist, x=\"sim\", nbins=len(sims_info_for_hist))\n",
    "fig.write_html(output_folder + 'sims_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sims_and_merge_clusters(sims_info, clusters, threshold, dialogs, n):\n",
    "    new_clusters = {}\n",
    "    cluster_id = 0\n",
    "    used_inds = []\n",
    "    is_merged = False\n",
    "    cluster_id_mapping = {}\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])} \n",
    "    for e in sims_info:\n",
    "        if e['sim'] >= threshold:\n",
    "            new_cluster = frozenset().union(reverse_index[e['source_ind']], reverse_index[e['target_ind']])\n",
    "            if new_cluster not in new_clusters:                \n",
    "                new_clusters[new_cluster] = cluster_id\n",
    "                cluster_id += 1\n",
    "                is_merged = True\n",
    "            used_inds += [e['source_ind'], e['target_ind']]\n",
    "            cluster_id_mapping[e['source_ind']] = new_clusters[new_cluster]\n",
    "            cluster_id_mapping[e['target_ind']] = new_clusters[new_cluster]\n",
    "    used_inds = set(used_inds)\n",
    "    for ind in reverse_index.keys():\n",
    "        if ind not in used_inds:\n",
    "            if reverse_index[ind] not in new_clusters:                \n",
    "                new_clusters[reverse_index[ind]] = cluster_id\n",
    "                cluster_id += 1\n",
    "            cluster_id_mapping[ind] = new_clusters[reverse_index[ind]]    \n",
    "    if is_merged is True:\n",
    "        at_least_one_with_thread_key = False\n",
    "        for dialog_id, dialog in dialogs.items():\n",
    "            key = get_thread_key(n)            \n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            else:\n",
    "                at_least_one_with_thread_key = True\n",
    "                thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):\n",
    "                row['cluster_id'] = cluster_id_mapping[row['cluster_id']]\n",
    "        assert at_least_one_with_thread_key\n",
    "        return filter_sims_and_merge_clusters(get_sims_info(new_clusters), new_clusters, threshold, dialogs, n)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = filter_sims_and_merge_clusters(sims_info, clusters, min_thresh, dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(new_clusters, dialogs, n=1):\n",
    "    cluster_ids = set()\n",
    "    key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_ids.add(row['cluster_id'])\n",
    "    assert len(cluster_ids) == len(new_clusters), print(len(cluster_ids), len(new_clusters))\n",
    "\n",
    "check_correctness(new_clusters, dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump new_clusters, old_clusters, dialogs, n, min_thresh, graphs\n",
    "\n",
    "def dump_data(n):\n",
    "    compressed_dialogs = {}\n",
    "    key = get_thread_key(n)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        compressed_thread = []\n",
    "        for ind, row in enumerate(thread):            \n",
    "            compressed_row = {'cluster_id': row['cluster_id']}\n",
    "            for i in range(n):\n",
    "                compressed_row[f'text{i}'] = row[f'text{i}']\n",
    "            compressed_thread.append(compressed_row)\n",
    "        compressed_dialogs[dialog_id] = {'thread': compressed_thread}\n",
    "    \n",
    "    res = joblib.dump(\n",
    "        {'new_clusters': new_clusters, 'clusters': clusters, 'n': n, 'min_thresh': min_thresh, 'dialog': compressed_dialogs},\n",
    "        data_path, \n",
    "    )\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    data = joblib.load(data_path)\n",
    "    return data\n",
    "\n",
    "dump_data(n)\n",
    "# data = load_data()\n",
    "# dialogs = data['dialogs']\n",
    "# new_clusters = data['new_clusters']\n",
    "# clusters = data['clusters']\n",
    "# n = data['n']\n",
    "# min_thresh = data['min_thresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index = {i: c for c, i in sorted(new_clusters.items(), key=lambda x: x[1])} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cluster_cluster_usage_distribution(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    cluster_usage_distribution = defaultdict(int)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_usage_distribution[row['cluster_id']] += 1\n",
    "    return cluster_usage_distribution\n",
    "\n",
    "cluster_usage_distribution = calc_cluster_cluster_usage_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [f\"c_{e}\" for e in list(cluster_usage_distribution.keys())]\n",
    "fig = px.histogram(x=xs, y=list(cluster_usage_distribution.values()), nbins=len(cluster_usage_distribution.keys()), labels={'x': 'cluster id'})\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.write_html(output_folder + 'usage_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_examples(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    cluster_examples = defaultdict(list)    \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):                \n",
    "                prev_texts = []\n",
    "                for i in range(0, n):\n",
    "                    text_key = f'text{i}'\n",
    "                    prev_texts.append(row[text_key])\n",
    "                cluster_examples[row['cluster_id']].append(prev_texts)\n",
    "    return cluster_examples\n",
    "\n",
    "cluster_examples = get_cluster_examples(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_features(dialogs, n):\n",
    "    key = get_thread_key(n)\n",
    "    orig_features = defaultdict(list)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "            if key not in dialog:\n",
    "                continue\n",
    "            thread = dialog[key]\n",
    "            for ind, row in enumerate(thread):          \n",
    "                orig_features[row['cluster_id']].append(row['final_features'])\n",
    "    return orig_features\n",
    "\n",
    "orig_features = get_original_features(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_by_turns_distribution(dialogs, n):\n",
    "    # { Cluster_id: {turn_num: count, ...}, ... }\n",
    "    key = get_thread_key(n)\n",
    "    cluster_turns_distr = defaultdict(dict)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):     \n",
    "            if ind not in cluster_turns_distr[row['cluster_id']]:\n",
    "                cluster_turns_distr[row['cluster_id']][ind] = 1\n",
    "            else:\n",
    "                cluster_turns_distr[row['cluster_id']][ind] += 1\n",
    "    return cluster_turns_distr\n",
    "cluster_turns_distr = get_cluster_by_turns_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_features_distribution(dialogs, n):\n",
    "    # {feature: [cluster_id1, cluster_id2, ...]}\n",
    "    key = get_thread_key(n)\n",
    "    features_distr = defaultdict(int)\n",
    "#     features_distr = defaultdict(set)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        if key not in dialog:\n",
    "            continue\n",
    "        thread = dialog[key]\n",
    "        for ind, row in enumerate(thread):  \n",
    "            for feature in row['final_features']:\n",
    "                features_distr[feature] += 1\n",
    "#                 features_distr[feature].add(row['cluster_id'])            \n",
    "    return features_distr\n",
    "features_distr = get_cluster_features_distribution(dialogs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_confidence(feature, cluster_id, features_distr, cluster_examples):    \n",
    "    final_cluster_size = len(cluster_examples[cluster_id])\n",
    "    features_before_clustering = orig_features[cluster_id]\n",
    "    n = 0\n",
    "    for fs in features_before_clustering:\n",
    "        if feature in fs:\n",
    "            n += 1\n",
    "    return round(n / final_cluster_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.9, 5.63)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mean_and_std_turn(cluster_turns_distr, cluster_id):\n",
    "    arr = []\n",
    "    for turn_num, count in cluster_turns_distr[cluster_id].items():\n",
    "        arr += [turn_num]*count\n",
    "    arr = np.array(arr)\n",
    "    return round(np.mean(arr), 1), round(np.std(arr), 2)\n",
    "\n",
    "get_mean_and_std_turn(cluster_turns_distr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coverage(top_k):\n",
    "    coverage = sum([freq for cluster_id, freq in sorted(cluster_usage_distribution.items(), key=lambda x: x[1], reverse=True)[:top_k]]) / sum(cluster_usage_distribution.values())\n",
    "    return round(coverage, 2)*100\n",
    "top_k = 10\n",
    "result_report = \"Help:\\n\"\n",
    "result_report += \"- Turn dist calculated as: Turn X freq / Frequency \\n\"\n",
    "result_report += \"- Feature confidence calculated as: min(1, number_of_clusters_that_has_this_feature / original total feature freq) \\n\"\n",
    "result_report += \"\\n\"\n",
    "result_report += f\"Threshold: {min_thresh}. Original clusters: {len(clusters)}. After merging: {len(new_clusters)}. \\n\"\n",
    "result_report += f\"Top-{top_k} clusters covers {calc_coverage(top_k)}% of data, top-25 {calc_coverage(25)}%, top-50 {calc_coverage(50)}% \\n\"\n",
    "result_report += \"\\n\"\n",
    "top_cluster_ids = []\n",
    "for cluster_id, freq in sorted(cluster_usage_distribution.items(), key=lambda x: x[1], reverse=True)[:top_k]:\n",
    "    if freq < 2:\n",
    "        continue\n",
    "    total_turns_count = len(cluster_turns_distr[cluster_id].values())    \n",
    "    result_report += f\"Cluster id: {cluster_id}; Frequency: {freq}; Present in {total_turns_count} turns.\\n \"\n",
    "    sorted_cluster_turns_distr = sorted(cluster_turns_distr[cluster_id].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    top_turns_count = [f\"Turn {turn_num} freq: {count}, dist: {round(count / freq, 2)}\" for turn_num, count in sorted_cluster_turns_distr]\n",
    "    mean_turn, std_turn = get_mean_and_std_turn(cluster_turns_distr, cluster_id)\n",
    "    result_report += f\"Mean turn: {mean_turn} +- {std_turn} \\n\"\n",
    "    result_report += \"Top 3 freq turns: \\n\"\n",
    "    for turn_num, count in sorted_cluster_turns_distr:\n",
    "        result_report += f\" - Turn {turn_num} freq: {count}, dist: {round(count / freq, 2)}\\n\"        \n",
    "    result_report += \"-------------\\n\"\n",
    "    for feature in sorted(reverse_index[cluster_id], key=lambda x: x[0]):        \n",
    "        result_report += f\"{feature}: {calc_feature_confidence(feature, cluster_id, features_distr, cluster_examples)}. \"\n",
    "        result_report += f'Orig freq: {features_distr[feature]}\\n'\n",
    "    result_report += \"Samples: \\n\"\n",
    "    for example_sentences in random.sample(cluster_examples[cluster_id], min(10, len(cluster_examples[cluster_id]))):\n",
    "        result_report += \"- \\n\"\n",
    "        for i, s in enumerate(example_sentences):        \n",
    "            result_report += f\"-- S{i}: {s} \\n\"        \n",
    "    result_report += \"-------------\\n\"\n",
    "    result_report += \"\\n\"\n",
    "    top_cluster_ids.append(cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SNG01856.json', 'SNG0129.json', 'PMUL1635.json']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dialogs.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in dialogs['PMUL1635.json']['thread1']:\n",
    "#     print(reverse_index[row['cluster_id']], row['cluster_id'])\n",
    "#     print('S0 ', row['text0'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help:\n",
      "- Turn dist calculated as: Turn X freq / Frequency \n",
      "- Feature confidence calculated as: min(1, number_of_clusters_that_has_this_feature / original total feature freq) \n",
      "\n",
      "Threshold: 0.74. Original clusters: 27. After merging: 27. \n",
      "Top-10 clusters covers 98.0% of data, top-25 100.0%, top-50 100.0% \n",
      "\n",
      "Cluster id: 25; Frequency: 81056; Present in 41 turns.\n",
      " Mean turn: 6.6 +- 5.03 \n",
      "Top 3 freq turns: \n",
      " - Turn 3 freq: 7601, dist: 0.09\n",
      " - Turn 1 freq: 7095, dist: 0.09\n",
      " - Turn 5 freq: 6952, dist: 0.09\n",
      "-------------\n",
      "0_dim_Task comm_func_Statement: 1.0. Orig freq: 85923\n",
      "Samples: \n",
      "- \n",
      "-- S0: Yes, there are 11 museums in the centre of town. What other information would you like? \n",
      "- \n",
      "-- S0: Warkworth does offer internet. \n",
      "- \n",
      "-- S0: OK, you're booked at the Holiday Inn, reference# W1TLHAWK. Can I help you with anything else today? \n",
      "- \n",
      "-- S0: Yes please. I need it for one person on Saturday. A 3 night stay. \n",
      "- \n",
      "-- S0: I have TR6416 that will get you to Cambridge by 07:52. Do you need any tickets today?  \n",
      "- \n",
      "-- S0: I'm sorry but I have a hard time believing there is no place to stay in the east with either a 3 or 4 star rating. \n",
      "- \n",
      "-- S0: Oh darn it! How about... maybe korean food? Still in the centre, and they need to be able to seat 7 people. \n",
      "- \n",
      "-- S0: Yes, I found what you're looking for. Would you like the address? \n",
      "- \n",
      "-- S0: I'm looking for a hotel with at least a three-star rating. \n",
      "- \n",
      "-- S0: There are 5 restaurants in the area. I like Frankie and Bennys in the south. Can I make you a reservation? \n",
      "-------------\n",
      "\n",
      "Cluster id: 22; Frequency: 23013; Present in 36 turns.\n",
      " Mean turn: 6.4 +- 5.12 \n",
      "Top 3 freq turns: \n",
      " - Turn 1 freq: 2412, dist: 0.1\n",
      " - Turn 2 freq: 2249, dist: 0.1\n",
      " - Turn 0 freq: 2072, dist: 0.09\n",
      "-------------\n",
      "0_dim_Task comm_func_Directive: 1.0. Orig freq: 24321\n",
      "Samples: \n",
      "- \n",
      "-- S0: The train should go to stevenage and should leave on friday.\n",
      "The train should depart from cambridge and should leave after 21:00 \n",
      "- \n",
      "-- S0: How about The Cambridge Belfry? \n",
      "- \n",
      "-- S0: I'm looking for a very nice place to dine. Something expensive. \n",
      "- \n",
      "-- S0: Glad I could help. Is there anything else I can do for you? \n",
      "- \n",
      "-- S0: Thanks for the info. Can you also tell me if there are any trains on Saturday that leave after 11:15? \n",
      "- \n",
      "-- S0: I would like to know more about a restaurant called the panahar if you could help?  \n",
      "- \n",
      "-- S0: How about a guesthouse instead? \n",
      "- \n",
      "-- S0: There are no restaurants that meet what you're looking for. Is there anything else you'd like to try? \n",
      "- \n",
      "-- S0: There are 23. What part of town would you like to stay in? \n",
      "- \n",
      "-- S0: Have a nice stay in Cambridge! \n",
      "-------------\n",
      "\n",
      "Cluster id: 19; Frequency: 16137; Present in 41 turns.\n",
      " Mean turn: 11.4 +- 5.35 \n",
      "Top 3 freq turns: \n",
      " - Turn 12 freq: 1659, dist: 0.1\n",
      " - Turn 14 freq: 1534, dist: 0.1\n",
      " - Turn 6 freq: 1488, dist: 0.09\n",
      "-------------\n",
      "0_dim_SocialObligationManagement comm_func_Thanking: 1.0. Orig freq: 19713\n",
      "Samples: \n",
      "- \n",
      "-- S0: Ok thats unreal,thank you anyway \n",
      "- \n",
      "-- S0: Thanks. Is there a british restaurant near the church I can eat at?  \n",
      "- \n",
      "-- S0: You're welcome. Have a great stay. \n",
      "- \n",
      "-- S0: Thank you, have a great day. \n",
      "- \n",
      "-- S0: Thank you for using our system! \n",
      "- \n",
      "-- S0: No, that's all I need. Thank you. \n",
      "- \n",
      "-- S0: Thank you, what time did the train depart? \n",
      "- \n",
      "-- S0: You're welcome. Have a great day! \n",
      "- \n",
      "-- S0: great day and thanks for inquiring with us \n",
      "- \n",
      "-- S0: No thank you, that is everything. \n",
      "-------------\n",
      "\n",
      "Cluster id: 20; Frequency: 6504; Present in 35 turns.\n",
      " Mean turn: 7.6 +- 4.98 \n",
      "Top 3 freq turns: \n",
      " - Turn 4 freq: 671, dist: 0.1\n",
      " - Turn 5 freq: 588, dist: 0.09\n",
      " - Turn 2 freq: 568, dist: 0.09\n",
      "-------------\n",
      "0_dim_Task comm_func_CheckQ: 1.0. Orig freq: 6779\n",
      "Samples: \n",
      "- \n",
      "-- S0: Can you give me the address, phone number, and entrance fee for Saint Catherine's College?   \n",
      "- \n",
      "-- S0:  Great, can I have their number, address,and postcode?  \n",
      "- \n",
      "-- S0: Do you have their phone number? \n",
      "- \n",
      "-- S0: could you give me the address, postcode, and phone number please? \n",
      "- \n",
      "-- S0: Can you give me the reference number for the train?  I would like cheap italian food in the center.   \n",
      "- \n",
      "-- S0: Can you give me the travel time on that? \n",
      "- \n",
      "-- S0: SURE AND CAN YOU CONFIRM THE PRICE FOR THE 15:24 TR9680 \n",
      "- \n",
      "-- S0: The telephone is 01223358966 and the address is Parkside, Cambridge. Is there anything else I can help you with?\n",
      " \n",
      "- \n",
      "-- S0: You're welcome. Is there anything else I can help with? \n",
      "- \n",
      "-- S0: That sounds good. May I have their telephone number? Also could you help me finding a 4 star hotel in the same area? \n",
      "-------------\n",
      "\n",
      "Cluster id: 26; Frequency: 3095; Present in 33 turns.\n",
      " Mean turn: 9.8 +- 5.68 \n",
      "Top 3 freq turns: \n",
      " - Turn 6 freq: 267, dist: 0.09\n",
      " - Turn 4 freq: 252, dist: 0.08\n",
      " - Turn 10 freq: 215, dist: 0.07\n",
      "-------------\n",
      "Samples: \n",
      "- \n",
      "-- S0: Just a moderately priced restaurant in the centre of town, Yippee Noodle Bar sounds good. If 16:15 doesn't work, I can change to 15:15. \n",
      "- \n",
      "-- S0: It would be great if it included wifi and was in the north. \n",
      "- \n",
      "-- S0: Alright, thanks. Are there any trains that run from Cambridge to birmingham new street? \n",
      "- \n",
      "-- S0: Sounds good. May I have the travel time and ticket price, please? \n",
      "- \n",
      "-- S0: Okay, have a great day! \n",
      "- \n",
      "-- S0: Have a nice day! \n",
      "- \n",
      "-- S0: A 4 star guesthouse in the north would be fine too.  \n",
      "- \n",
      "-- S0: Excellent. I hope you have a great rest of your day! \n",
      "- \n",
      "-- S0: Hey!  Yeah I am looking for a cheap place to eat in Cambridge.  Particularly interested in international food. \n",
      "- \n",
      "-- S0: I don't think that matters. Can you just make sure I leave the restaurant to the hotel no later than 24:30.  \n",
      "-------------\n",
      "\n",
      "Cluster id: 13; Frequency: 2908; Present in 32 turns.\n",
      " Mean turn: 10.3 +- 6.36 \n",
      "Top 3 freq turns: \n",
      " - Turn 0 freq: 347, dist: 0.12\n",
      " - Turn 15 freq: 284, dist: 0.1\n",
      " - Turn 13 freq: 264, dist: 0.09\n",
      "-------------\n",
      "0_dim_SocialObligationManagement comm_func_Salutation: 1.0. Orig freq: 4214\n",
      "Samples: \n",
      "- \n",
      "-- S0: Thank you, that's all I need. Good bye. \n",
      "- \n",
      "-- S0: Perfect! That's all I need. See you later. Bye.  \n",
      "- \n",
      "-- S0: You are welcome. I hope you feel better soon. Goodbye. \n",
      "- \n",
      "-- S0: Your welcome. Have a great day. \n",
      "- \n",
      "-- S0: Thank you, that's all I need. Good bye. \n",
      "- \n",
      "-- S0: You are welcome. Enjoy your stay. \n",
      "- \n",
      "-- S0: You are very welcome! Have a great time! Goodbye!  \n",
      "- \n",
      "-- S0: Hello, I am looking for a train that is leaving after 14:00 on Friday. \n",
      "- \n",
      "-- S0: You're very welcome. Good day. \n",
      "- \n",
      "-- S0: Oh, you are most welcome. The museum will be awesome.  \n",
      "-------------\n",
      "\n",
      "Cluster id: 18; Frequency: 2653; Present in 33 turns.\n",
      " Mean turn: 9.7 +- 5.79 \n",
      "Top 3 freq turns: \n",
      " - Turn 6 freq: 320, dist: 0.12\n",
      " - Turn 12 freq: 284, dist: 0.11\n",
      " - Turn 10 freq: 261, dist: 0.1\n",
      "-------------\n",
      "0_dim_Task comm_func_Statement: 1.0. Orig freq: 85923\n",
      "0_dim_SocialObligationManagement comm_func_Thanking: 1.0. Orig freq: 19713\n",
      "Samples: \n",
      "- \n",
      "-- S0: No, I just needed the phone number. Thanks very much for your help. \n",
      "- \n",
      "-- S0: I need to arrive at the airport by 13:15.  Can I get a departure time and also the travel time for a train?  Thanks! \n",
      "- \n",
      "-- S0: Hi, I am trying to plan a trip and could use some help with the trains. \n",
      "- \n",
      "-- S0: That will be all thank you for your help.  \n",
      "- \n",
      "-- S0: That is all I need today thank you for your help.  \n",
      "- \n",
      "-- S0: Thanks. What is the postcode and address? \n",
      "- \n",
      "-- S0: Thank you I need to book four people for 2 nights starting saturday \n",
      "- \n",
      "-- S0: I'm sorry, but I actually needed the hotel for 4 nights, can you adjust that for me? \n",
      "- \n",
      "-- S0: No thanks, that's all I need for now. \n",
      "- \n",
      "-- S0: Thank you very much. That will be all for today. I appreciate all your help. \n",
      "-------------\n",
      "\n",
      "Cluster id: 2; Frequency: 1725; Present in 31 turns.\n",
      " Mean turn: 8.9 +- 5.63 \n",
      "Top 3 freq turns: \n",
      " - Turn 2 freq: 204, dist: 0.12\n",
      " - Turn 4 freq: 202, dist: 0.12\n",
      " - Turn 6 freq: 154, dist: 0.09\n",
      "-------------\n",
      "0_dim_Feedback comm_func_Feedback: 1.0. Orig freq: 1737\n",
      "Samples: \n",
      "- \n",
      "-- S0: Okay perfect. Have a great day, goodbye.  \n",
      "- \n",
      "-- S0: Yes, that would be great.  I need to make it to the restaurant by 11:15.  \n",
      "- \n",
      "-- S0: That's wonderful. And the taxi will arrive by 15:30, right?  \n",
      "- \n",
      "-- S0: I'm really not to sure.  \n",
      "- \n",
      "-- S0: No problem, have a wonderful day! \n",
      "- \n",
      "-- S0: i am glad i have been of help. good day \n",
      "- \n",
      "-- S0: okay the first train leaves the station at 5:40 the last 09:40 \n",
      "- \n",
      "-- S0: Maybe a museum would be nice. I am not sure. \n",
      "- \n",
      "-- S0: Yes, I would prefer the north. \n",
      "- \n",
      "-- S0: Sure, a turkish restaurant in the moderate price range would be great. \n",
      "-------------\n",
      "\n",
      "Cluster id: 6; Frequency: 1295; Present in 30 turns.\n",
      " Mean turn: 7.4 +- 5.27 \n",
      "Top 3 freq turns: \n",
      " - Turn 1 freq: 187, dist: 0.14\n",
      " - Turn 3 freq: 185, dist: 0.14\n",
      " - Turn 5 freq: 159, dist: 0.12\n",
      "-------------\n",
      "0_dim_SocialObligationManagement comm_func_Apology: 1.0. Orig freq: 1917\n",
      "0_dim_Task comm_func_Statement: 1.0. Orig freq: 85923\n",
      "Samples: \n",
      "- \n",
      "-- S0: I'm sorry, I can't find any place with Corsica food. Do you have a second choice? \n",
      "- \n",
      "-- S0: I am sorry but the Golden House was not available on Sunday at 12:00. Can I find another restaurant for you perhaps? \n",
      "- \n",
      "-- S0: I'm sorry, there is no guest house that meets those criteria, either. Would you like to try a different rating, or a different area? \n",
      "- \n",
      "-- S0: i'm sorry, someone entered the incorrect info. i can actually get you there by 10:08 on the TR2755 train. \n",
      "- \n",
      "-- S0: I'm sorry.  First I need to find a hospital. \n",
      "- \n",
      "-- S0: I'm sorry, that reservation wasn't available. Perhaps you could book another day, or a different length of stay? \n",
      "- \n",
      "-- S0: I'm sorry I didn't pull up any matches.  \n",
      "- \n",
      "-- S0: I's sorry, I meant to say LEAVING from Cambridge on Tuesday, heading to King's Lynn. I need to arrive by 16:00. \n",
      "- \n",
      "-- S0: I'm sorry, I will be departing from the hotel to the restaurant. I don't mind what time it leaves as long as I get to the restaurant by 13:30.  \n",
      "- \n",
      "-- S0: Er, sorry, I actually needed that train on Sunday, not Friday.  \n",
      "-------------\n",
      "\n",
      "Cluster id: 21; Frequency: 1252; Present in 28 turns.\n",
      " Mean turn: 7.8 +- 5.22 \n",
      "Top 3 freq turns: \n",
      " - Turn 2 freq: 150, dist: 0.12\n",
      " - Turn 6 freq: 110, dist: 0.09\n",
      " - Turn 4 freq: 102, dist: 0.08\n",
      "-------------\n",
      "0_dim_Task comm_func_Commissive: 1.0. Orig freq: 1280\n",
      "Samples: \n",
      "- \n",
      "-- S0: Sure thing, I have three options would you like me to book one for you? \n",
      "- \n",
      "-- S0: I'll take one with an entrance fee, and I'll need the postcode, and phone number please. \n",
      "- \n",
      "-- S0: Um, I think I'll just take the postcode and the name for now thanks. \n",
      "- \n",
      "-- S0: I will do that for you now. \n",
      "- \n",
      "-- S0: Just to be sure a yellow taxi will get me from aylesbray lodge guest house to Ask by 12:15, correct? \n",
      "- \n",
      "-- S0: I will book it for you now. \n",
      "- \n",
      "-- S0: I'll be starting my stay on this coming Sunday. \n",
      "- \n",
      "-- S0: Sure thing!  Can I help you with anything else?   \n",
      "- \n",
      "-- S0: Let's book a train, I'll be departing from cambridge and going to broxbourne. Lets look for something on wednesday arriving in broxbourne by 19:00. \n",
      "- \n",
      "-- S0: Do you want me to book that hotel for you? \n",
      "-------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(output_folder + f'{output_key}_n-{n}_{features_name}_report.txt', 'w') as f:\n",
    "    print(result_report, file=f)\n",
    "print(result_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
