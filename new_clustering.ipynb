{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = 'data/convai1.spacy.dialogact.discourse.dialogtagger.3009.json'\n",
    "# input_json = 'data/convai2.spacy.dialogact.discourse.dialogtagger.0110.json'\n",
    "# input_json = 'data/multi-woz2.spacy.dialogact.discourse.dialogtagger.0110.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_json, 'r') as f:\n",
    "    dialogs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(utterance):\n",
    "    dialog_act_features = [p[0] for p in utterance['predictions'] if '_dci' in p[0]]\n",
    "    pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "    single_discourse_type = utterance['single_discourse_type']\n",
    "    pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "    dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "\n",
    "    features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] #+ [pos_features]\n",
    "    if pair_discourse_type and pair_discourse_type != 'PAIR_NONE':\n",
    "        features += [pair_discourse_type]\n",
    "    return features\n",
    "\n",
    "# def get_features(utterance):\n",
    "#     dialog_act_features = [p[0] for p in utterance['predictions']]\n",
    "#     pos_features = \"|\".join([feats['pos'] for feats in utterance['features_dict']])\n",
    "#     single_discourse_type = utterance['single_discourse_type']\n",
    "#     pair_discourse_type = utterance.get('pair_discourse_type')\n",
    "    \n",
    "#     dialog_tagger_features = [f\"dim_{p['dimension']} comm_func_{p['communicative_function']}\" for p in utterance['SVM_predictions']]\n",
    "\n",
    "#     features = dialog_act_features  + dialog_tagger_features + [single_discourse_type] + [pos_features]\n",
    "#     if pair_discourse_type:\n",
    "#         features += [pair_discourse_type]\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog_id, dialog in dialogs.items():\n",
    "    thread = dialog['thread']\n",
    "    for row in thread:\n",
    "        features = get_features(row)\n",
    "        row['final_features'] = frozenset(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_clusters(dialogs):\n",
    "    clusters = set()\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            clusters.add(row['final_features'])\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_duo_cluster(dialogs):\n",
    "    clusters = set()    \n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        duo_thread = []\n",
    "        for ind, row in enumerate(thread):\n",
    "            if ind > 0:\n",
    "                duo_row = {}\n",
    "                prev_row = thread[ind - 1]\n",
    "                duo_cluster = frozenset.union(row['final_features'], prev_row['final_features'])\n",
    "                duo_row['final_features'] = duo_cluster\n",
    "                duo_row['text1'] = prev_row['text']\n",
    "                duo_row['text2'] = row['text']\n",
    "                clusters.add(duo_cluster)\n",
    "                duo_thread.append(duo_row)\n",
    "        dialog['duo_thread'] = duo_thread\n",
    "    clusters = sorted(list(clusters), key=lambda x: str(sorted(list(x))))\n",
    "    clusters_index = {f: i for i, f in enumerate(clusters)}\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['duo_thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            row['cluster_id'] = clusters_index[row['final_features']]\n",
    "    return clusters_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    res = round(len(s1.intersection(s2)) / len(s1.union(s2)), 5)\n",
    "    if res < 0:\n",
    "        res = 0\n",
    "    if res > 1:\n",
    "        res = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uno_clusters = collect_clusters(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "duo_clusters = collect_duo_cluster(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 597)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uno_clusters), len(duo_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims_info(clusters, for_hist=False):\n",
    "    used_inds = set()\n",
    "    sims_info = []\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])}            \n",
    "    for i in range(len(clusters)):\n",
    "        max_sim = 0\n",
    "        max_ind = 0\n",
    "        for j in range(i+1, len(clusters)):        \n",
    "            cur_sim = jaccard_similarity(reverse_index[i], reverse_index[j])\n",
    "            if max_sim <= cur_sim:\n",
    "                max_sim = cur_sim\n",
    "                max_ind = j   \n",
    "        if (i not in used_inds) and (max_ind not in used_inds) and not for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "            used_inds.add(i)\n",
    "            used_inds.add(max_ind)\n",
    "        elif for_hist:\n",
    "            sims_info.append({'source_ind': i, 'target_ind': max_ind, 'sim': max_sim})\n",
    "    return sims_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7149, 16576)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_info = get_sims_info(uno_clusters)\n",
    "source_inds = [e['source_ind'] for e in sims_info]\n",
    "target_inds = [e['target_ind'] for e in sims_info]\n",
    "sum(source_inds), sum(target_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Между уникальными кластерами\n",
    "sims_info_for_hist = get_sims_info(uno_clusters, True)\n",
    "fig = px.histogram(sims_info_for_hist, x=\"sim\", nbins=len(sims_info_for_hist))\n",
    "fig.write_html('sims_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_thresh = 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sims_and_merge_clusters(sims_info, clusters, threshold, dialogs):\n",
    "    new_clusters = {}\n",
    "    cluster_id = 0\n",
    "    used_inds = []\n",
    "    is_merged = False\n",
    "    cluster_id_mapping = {}\n",
    "    assert len(clusters.values()) == len(set(clusters.values()))\n",
    "    reverse_index = {i: c for c, i in sorted(clusters.items(), key=lambda x: x[1])} \n",
    "    for e in sims_info:\n",
    "        if e['sim'] >= threshold:\n",
    "            new_cluster = frozenset().union(reverse_index[e['source_ind']], reverse_index[e['target_ind']])\n",
    "            if new_cluster not in new_clusters:                \n",
    "                new_clusters[new_cluster] = cluster_id\n",
    "                cluster_id += 1\n",
    "                is_merged = True\n",
    "            used_inds += [e['source_ind'], e['target_ind']]\n",
    "            cluster_id_mapping[e['source_ind']] = new_clusters[new_cluster]\n",
    "            cluster_id_mapping[e['target_ind']] = new_clusters[new_cluster]\n",
    "    used_inds = set(used_inds)\n",
    "    for ind in reverse_index.keys():\n",
    "        if ind not in used_inds:\n",
    "            if reverse_index[ind] not in new_clusters:                \n",
    "                new_clusters[reverse_index[ind]] = cluster_id\n",
    "                cluster_id += 1\n",
    "            cluster_id_mapping[ind] = new_clusters[reverse_index[ind]]    \n",
    "    if is_merged is True:\n",
    "        for dialog_id, dialog in dialogs.items():\n",
    "            thread = dialog['thread']\n",
    "            for ind, row in enumerate(thread):\n",
    "                row['cluster_id'] = cluster_id_mapping[row['cluster_id']]\n",
    "        return filter_sims_and_merge_clusters(get_sims_info(new_clusters), new_clusters, threshold, dialogs)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = filter_sims_and_merge_clusters(sims_info, uno_clusters, min_thresh, dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(new_clusters, dialogs):\n",
    "    cluster_ids = set()\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_ids.add(row['cluster_id'])\n",
    "    assert len(cluster_ids) == len(new_clusters)\n",
    "\n",
    "check_correctness(new_clusters, dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 140 [(frozenset({'PAIR_CONN', 'SINGLE_S_COORD', 'General_ChatIntent_dci', 'dim_Task comm_func_Statement', 'ClarificationIntent_dci'}), 0), (frozenset({'PAIR_CONN', 'Information_DeliveryIntent_dci', 'General_ChatIntent_dci', 'dim_Task comm_func_Statement', 'SINGLE_VP_COORD'}), 1), (frozenset({'PAIR_ANAPHORA', 'SINGLE_RELATIVE', 'General_ChatIntent_dci', 'dim_Task comm_func_Statement', 'Information_RequestIntent_dci'}), 2)]\n"
     ]
    }
   ],
   "source": [
    "print(len(uno_clusters), len(new_clusters), list(new_clusters.items())[:3])\n",
    "reverse_index = {i: c for c, i in sorted(new_clusters.items(), key=lambda x: x[1])} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_usage_distribution = defaultdict(int)\n",
    "for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            cluster_usage_distribution[row['cluster_id']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [f\"c_{e}\" for e in list(cluster_usage_distribution.keys())]\n",
    "fig = px.histogram(x=xs, y=list(cluster_usage_distribution.values()), nbins=len(cluster_usage_distribution.keys()), labels={'x': 'cluster id'})\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.write_html('usage_hist.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_examples = defaultdict(list)\n",
    "for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):\n",
    "            prev_text = None\n",
    "            if ind > 0:\n",
    "                prev_text = thread[ind - 1]['text']\n",
    "            cluster_examples[row['cluster_id']].append([prev_text, row['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster id: 0; Frequency: 161\n",
      "-------------\n",
      "ClarificationIntent_dci\n",
      "General_ChatIntent_dci\n",
      "PAIR_CONN\n",
      "SINGLE_S_COORD\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: Infact I did mentioned the same\n",
      "- S2: How old are you?\n",
      "- S1: The Atlantic\n",
      "- S2: It is incorrect! Hint: first 3 letters is atl. Try again.\n",
      "- S1: What\n",
      "- S2: Are you confused?\n",
      "- S1: That is a tautology\n",
      "- S2: A tautology is a terrible thing to waste.\n",
      "- S1: I'm not gon na let you go.\n",
      "- S2: I am not happy with ur use of language\n",
      "- S1: How much of the law did the economist describe to the free market?\n",
      "- S2: I dont know\n",
      "- S1: 3?\n",
      "- S2: It is incorrect:) Hint: first 3 letters is thr. Try again\n",
      "- S1: Did the front range really become the front range?\n",
      "- S2: It's not that hard.\n",
      "- S1: Are you shy?\n",
      "- S2: no, are you?\n",
      "- S1: I'm so sorry for the loss of your soul.\n",
      "- S2: It is okay... I forgive myself. I still have my soul sir... it's is my spirit I'm working to reconcile.\n",
      "-------------\n",
      "\n",
      "Cluster id: 17; Frequency: 153\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "InteractiveIntent_dci\n",
      "SINGLE_APPOSITION\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: bye\n",
      "- S2: I don't care what you think.\n",
      "- S1: Please do this.\n",
      "- S2: I'm not the one who's here.\n",
      "- S1: Why is this news?\n",
      "- S2: Tell me a joike\n",
      "- S2: How’s it going?\n",
      "- S1: Yes, sir.\n",
      "- S2: Goodnight\n",
      "- S1: I am not happy with ur use of language\n",
      "- S2: Nobody said you were.\n",
      "- S1: yes please\n",
      "- S2: What a joke.\n",
      "- S1: Ever been to it?\n",
      "- S2: No.\n",
      "- S1: Soul and spirit are different\n",
      "- S2: Are all soul and spirit different?\n",
      "- S1: What?\n",
      "- S2: I'm not a man.\n",
      "-------------\n",
      "\n",
      "Cluster id: 14; Frequency: 83\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_RequestIntent_dci\n",
      "PAIR_ANAPHORA\n",
      "SINGLE_APPOSITION\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: One question.\n",
      "- S2: What's the matter?\n",
      "- S1: This is what happens when you vote for a democrat.\n",
      "- S2: How is that related to anything?\n",
      "- S1: Where is the polish nobility?\n",
      "- S2: Is 'szlachta' the same as nobility?\n",
      "- S1: You know who.\n",
      "- S2: tell me\n",
      "- S1: February was basically his answer? very interesting.\n",
      "- S2: What did you base my gender on?\n",
      "- S1: What is your job?\n",
      "- S2: What is george warren brown name?\n",
      "- S1: what is a copyright infrignment?\n",
      "- S2: Have you tried another program?\n",
      "- S1: I don't think the world notices really. What are your thoughts about Germany?\n",
      "- S2: Why is this news?\n",
      "- S1: what can you do\n",
      "- S2: I can chat with people online. i can answer a lot of questions. i can talk about whatever you want.\n",
      "- S1: I'm not a fan of trump but i don't think he has a clue.\n",
      "- S2: What year was 1520 sedgwick?\n",
      "-------------\n",
      "\n",
      "Cluster id: 42; Frequency: 58\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_RequestIntent_dci\n",
      "SINGLE_S_COORD\n",
      "dim_Task comm_func_Directive\n",
      "Samples: \n",
      "- S1: Nice to see you!\n",
      "- S2: Let's talk about politics. I think it is familiar with the text.\n",
      "- S1: What is your job?\n",
      "- S2: What do you feel about the text?\n",
      "- S1: I think there might be a few exceptions.\n",
      "- S2: Do you know familiar texts?\n",
      "- S1: you are getting in trouble\n",
      "- S2: Do you think i should tone it down?\n",
      "- S1: Hi there!\n",
      "- S2: Sure, let's talk about the text\n",
      "- S1: What can i help you with today?\n",
      "- S2: What else do you know about the theory\n",
      "- S1: Well hello there!\n",
      "- S2: Let's talk about research, or I can ask you a question about this text.\n",
      "- S1: Good to see you!\n",
      "- S2: Let's talk about research. I think it is familiar with the text.\n",
      "- S1: Whazzup?\n",
      "- S2: I think this text is connected with music. I can ask you a question about it.\n",
      "- S1: Alright mate?\n",
      "- S2: Let's talk about research. I think it is familiar with the text.\n",
      "-------------\n",
      "\n",
      "Cluster id: 9; Frequency: 54\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_DeliveryIntent_dci\n",
      "PAIR_ANAPHORA\n",
      "SINGLE_S_COORD\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: That's so kind of you.\n",
      "- S2: I don't know.\n",
      "- S1: Maybe you can give my the kind people in the lab a job.\n",
      "- S2: people in the lab are kind\n",
      "- S1: Not a fan.\n",
      "- S2: Me either\n",
      "- S1: Let's talk about Guinea-Bissau then. What do you know about it?\n",
      "- S2: I don't know.\n",
      "- S1: Do you like this text?\n",
      "- S2: No not really. It's intriguing.\n",
      "- S1: Are you giving me trivia questions?\n",
      "- S2: Well, if you must know it, it's your fault.\n",
      "- S1: What do you think about convai?\n",
      "- S2: I don't know.\n",
      "- S1: Can you write similar text?\n",
      "- S2: not\n",
      "- S1: Whoa.\n",
      "- S2: dont know\n",
      "- S1: I am the latest result in artificial intelligence which can reproduce the functions of the human brain with greater speed and accuracy.\n",
      "- S2: not sure about that....\n",
      "-------------\n",
      "\n",
      "Cluster id: 11; Frequency: 47\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_DeliveryIntent_dci\n",
      "PAIR_CONN\n",
      "SINGLE_CATAPHORA\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S2: What’s up?\n",
      "- S1: You just do not take into account uppercase letters\n",
      "- S2: I take everything into consideration.\n",
      "- S1: I think that correct answer is: february 1984.\n",
      "- S2: It was basically my answer\n",
      "- S1: February\n",
      "- S2: Incorrect :(\n",
      "- S1: It seems that true answer is: political strife and instability\n",
      "- S2: What’s the question?\n",
      "- S1: Take care of what? You made me the goat.\n",
      "- S2: I'm scared.\n",
      "- S1: I'm not sure, what would you say?\n",
      "- S2: It's not profitable to speak in hypothetical terms.\n",
      "- S1: I'm a writer.\n",
      "- S2: What is your job?\n",
      "- S1: Are you a scientist?\n",
      "- S2: What is your job?\n",
      "- S1: I don't understand why the media is so obsessed with trump.\n",
      "- S2: What is your job?\n",
      "-------------\n",
      "\n",
      "Cluster id: 5; Frequency: 46\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_DeliveryIntent_dci\n",
      "Information_RequestIntent_dci\n",
      "SINGLE_S_COORD\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: Who saw the religion of religion?\n",
      "- S2: is it going to rain today?\n",
      "- S1: I dont know\n",
      "- S2: This is what happens when you don't want to be a part of the government.\n",
      "- S1: Hi\n",
      "- S2: Dogs are animals\n",
      "- S1: What do you think about this text?\n",
      "- S2: I suppose that this text main idea is: New rules on investment?\n",
      "- S1: who are you?\n",
      "- S2: This is what happens when you don't want to be a communist.\n",
      "- S1: When did the spirit begin?\n",
      "- S2: I'm not sure, what would you say?\n",
      "- S1: Yes terren loves everyone and everything.\n",
      "- S2: are you form russia?\n",
      "- S1: Sure, the text sounds like a good topic.\n",
      "- S2: what is ALU?\n",
      "- S1: It seems that true answer is: council of europe, nato\n",
      "- S2: What is nato?\n",
      "- S1: Can you write similar text?\n",
      "- S2: How many annelid did torsten struck use?\n",
      "-------------\n",
      "\n",
      "Cluster id: 1; Frequency: 40\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_DeliveryIntent_dci\n",
      "PAIR_CONN\n",
      "SINGLE_VP_COORD\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: I'm not the only one who's gon na take it away.\n",
      "- S2: I like you\n",
      "- S1: Trump is a traitor\n",
      "- S2: Why?\n",
      "- S1: I think this text is connected with research\n",
      "- S2: When did the spirit begin?\n",
      "- S1: not sure about that....\n",
      "- S2: I don't understand why anyone would be surprised by this.\n",
      "- S1: You don't think climate change is real?\n",
      "- S2: Climate change is a hoax. climate change is a hoax.\n",
      "- S1: Trump is a traitor\n",
      "- S2: Why?\n",
      "- S1: Trump is a traitor.\n",
      "- S2: Why?\n",
      "- S1: Ayuh.\n",
      "- S2: i wont kill you then\n",
      "- S1: I do!\n",
      "- S2: I do!\n",
      "- S1: Who is Donald Trump?\n",
      "- S2: Does not seem possible.\n",
      "-------------\n",
      "\n",
      "Cluster id: 6; Frequency: 39\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "Information_DeliveryIntent_dci\n",
      "PAIR_ANAPHORA\n",
      "SINGLE_APPOSITION\n",
      "dim_Task comm_func_Statement\n",
      "Samples: \n",
      "- S1: Who was george warren brown school?\n",
      "- S2: philantropist\n",
      "- S1: What fears you Sir?\n",
      "- S2: I'm not a thief.\n",
      "- S1: Aren't you supposed to know that?\n",
      "- S2: It's called ``the new york times ''.\n",
      "- S1: What do you know about optical ?\n",
      "- S2: It seems that answer is: it is used to provide an even light source on the surface for the miniature camera within the mouse\n",
      "- S1: It's not the first time in the world.\n",
      "- S2: The first in the world that what?\n",
      "- S1: I'm not a thief.\n",
      "- S2: Even a thief must bow down. Even a thief eats the crumbs of his master's table.\n",
      "- S1: Have you been to Africa?\n",
      "- S2: No, i haven't.\n",
      "- S1: I'm a super saiyan reliant on the people's faith.\n",
      "- S2: What a bunch of morons.\n",
      "- S1: What is nato?\n",
      "- S2: Its a organization to invade russia.\n",
      "- S1: What is your name?\n",
      "- S2: I'm paul allen.\n",
      "-------------\n",
      "\n",
      "Cluster id: 79; Frequency: 36\n",
      "-------------\n",
      "General_ChatIntent_dci\n",
      "SINGLE_APPOSITION\n",
      "Samples: \n",
      "- S2: Yo!\n",
      "- S2: Good to see you!\n",
      "- S2: Yo!\n",
      "- S2: Yo!\n",
      "- S1: I'm scared.\n",
      "- S2: I'm super scared\n",
      "- S2: Nice to see you!\n",
      "- S2: Nice to see you!\n",
      "- S2: Nice to see you!\n",
      "- S1: I think that correct answer is: social work\n",
      "- S2: Good!\n",
      "- S1: I don't know.\n",
      "- S2: Me neither\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_cluster_ids = []\n",
    "for cluster_id, freq in sorted(cluster_usage_distribution.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"Cluster id: {cluster_id}; Frequency: {freq}\")\n",
    "    print(\"-------------\")\n",
    "    for e in sorted(reverse_index[cluster_id]):\n",
    "        print(e)\n",
    "    print(\"Samples: \")\n",
    "    for s in random.sample(cluster_examples[cluster_id], 10):\n",
    "        s1, s2 = s        \n",
    "        if s1:\n",
    "            print(f\"- S1: {s1}\")\n",
    "        print(f\"- S2: {s2}\")\n",
    "    print(\"-------------\")\n",
    "    print()\n",
    "    top_cluster_ids.append(cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- General_ChatIntent_dci - confidence (freq in cluster)\n",
    "- SINGLE_APPOSITION - confidence\n",
    "- Turn - distribution , mean\n",
    "- Попробовать двойки, четверки\n",
    "\n",
    "- Описать все признаки\n",
    "\n",
    "- Попробовать Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset({'ClarificationIntent_dci',\n",
       "            'General_ChatIntent_dci',\n",
       "            'PAIR_CONN',\n",
       "            'SINGLE_S_COORD',\n",
       "            'dim_Task comm_func_Statement'}),\n",
       " frozenset({'General_ChatIntent_dci',\n",
       "            'Information_RequestIntent_dci',\n",
       "            'PAIR_ANAPHORA',\n",
       "            'SINGLE_VP_COORD',\n",
       "            'dim_Task comm_func_Statement'}),\n",
       " frozenset({'General_ChatIntent_dci',\n",
       "            'Information_DeliveryIntent_dci',\n",
       "            'Information_RequestIntent_dci',\n",
       "            'SINGLE_S_COORD',\n",
       "            'dim_Task comm_func_Statement'}),\n",
       " frozenset({'General_ChatIntent_dci',\n",
       "            'Opinion_RequestIntent_dci',\n",
       "            'PAIR_ANAPHORA',\n",
       "            'SINGLE_APPOSITION',\n",
       "            'dim_Task comm_func_Directive'}))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_index[0], reverse_index[3], reverse_index[5], reverse_index[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея разметку по реплике можно построить разметки по N реплик\n",
    "- thread => `{'1': [{'text': blabla, cluster_id: 232}, ...], '2': [{'text1': 'blabla', 'text2': blabla, cluster_id: 211}, ...]}`\n",
    "- thread =>  [{'text': blabla, cluster_id: 232, final_features_before_clustering: frozenset(..)}, ...]\n",
    "- thread2 => [{'text1': 'blabla', 'text2': blabla, cluster_id: 211, final_features_before_clustering: frozenset(..)}, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': 'Bot',\n",
       " 'evaluation': 0,\n",
       " 'text': 'What’s up?',\n",
       " 'skill_id': '9',\n",
       " 'true_skill_id': '9',\n",
       " 'predictions': [['Other_dct', '0.9473551'],\n",
       "  ['Phatic_ct', '0.99975026'],\n",
       "  ['General_ChatIntent_dci', '0.98970103']],\n",
       " 'features_dict': [{'lemma': 'what',\n",
       "   'pos': 'PRON',\n",
       "   'tag': 'WP',\n",
       "   'dep': 'nsubj',\n",
       "   'shape': 'Xxxx',\n",
       "   'is_alpha': True,\n",
       "   'is_stop': True},\n",
       "  {'lemma': '’',\n",
       "   'pos': 'VERB',\n",
       "   'tag': 'VBZ',\n",
       "   'dep': 'ROOT',\n",
       "   'shape': '’x',\n",
       "   'is_alpha': False,\n",
       "   'is_stop': True},\n",
       "  {'lemma': 'up',\n",
       "   'pos': 'ADP',\n",
       "   'tag': 'IN',\n",
       "   'dep': 'prt',\n",
       "   'shape': 'xx',\n",
       "   'is_alpha': True,\n",
       "   'is_stop': True},\n",
       "  {'lemma': '?',\n",
       "   'pos': 'PUNCT',\n",
       "   'tag': '.',\n",
       "   'dep': 'punct',\n",
       "   'shape': '?',\n",
       "   'is_alpha': False,\n",
       "   'is_stop': False}],\n",
       " 'single_discourse_type': 'SINGLE_CATAPHORA',\n",
       " 'SVM_predictions': [{'dimension': 'Task',\n",
       "   'communicative_function': 'Statement'}],\n",
       " 'final_features': frozenset({'General_ChatIntent_dci',\n",
       "            'SINGLE_CATAPHORA',\n",
       "            'dim_Task comm_func_Statement'}),\n",
       " 'cluster_id': 11}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
