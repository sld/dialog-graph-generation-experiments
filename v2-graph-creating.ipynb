{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(output_key='topicalchat', feature_name='discourse_features', n=2):     \n",
    "    # output_key = 'multi-woz2'\n",
    "    # output_key = 'topicalchat'\n",
    "    # features_name = 'dialog_tagger_features'\n",
    "    # features_name = 'discourse_features'\n",
    "    # features_name = 'topic_model_features'    \n",
    "    output_folder = f'data/results/{output_key}_{n}_{feature_name}/'    \n",
    "    data_path = output_folder + 'data.joblib'\n",
    "    return data_path\n",
    "\n",
    "def get_output_path(output_key='topicalchat', feature_name='discourse_features', n=2):     \n",
    "    # output_key = 'multi-woz2'\n",
    "    # output_key = 'topicalchat'\n",
    "    # features_name = 'dialog_tagger_features'\n",
    "    # features_name = 'discourse_features'\n",
    "    # features_name = 'topic_model_features'    \n",
    "    output_folder = f'data/results/{output_key}_{n}_{feature_name}/'    \n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = joblib.load(data_path)\n",
    "    return data\n",
    "\n",
    "def jaccard_similarity(s1, s2):    \n",
    "    if not s1 and not s2:\n",
    "        return 0\n",
    "    res = round(len(s1.intersection(s2)) / len(s1.union(s2)), 5)\n",
    "    if res < 0:\n",
    "        res = 0\n",
    "    if res > 1:\n",
    "        res = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'topicalchat'\n",
    "feature_name_1 = 'dialog_tagger_features'\n",
    "n = 1\n",
    "f1_data_path = get_data_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "f1_output_path = get_output_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "f1_data = load_data(f1_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_index_f1 = {i: c for c, i in sorted(f1_data['new_clusters'].items(), key=lambda x: x[1])} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_graph_dict(graph_dict):\n",
    "    weights = [v for k, v in graph_dict.items()]\n",
    "    max_weight = max(weights)\n",
    "    min_weight = min(weights)\n",
    "#     second_max_weight = sorted(weights)[-2]\n",
    "#     denom = max_weight - min_weight\n",
    "    denom = max_weight\n",
    "#     denom = second_max_weight\n",
    "#     return {(k[0], k[1]): round(v / denom, 10) for k, v in graph_dict.items()}\n",
    "    return {(k[0], k[1]): np.log(v+1) for k, v in graph_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes1 = ['Statement',\n",
    " 'Directive',\n",
    " 'Thanking',\n",
    " 'CheckQ',\n",
    " 'Feedback',\n",
    " 'Salutation',\n",
    " 'Commissive',\n",
    " 'Apology',\n",
    " 'SetQ',\n",
    " 'PropQ']\n",
    "\n",
    "nodes2 = ['Statement',\n",
    " 'Directive',\n",
    " 'Thanking',\n",
    " 'CheckQ',\n",
    " 'Feedback',\n",
    " 'Salutation',\n",
    " 'Commissive',\n",
    " 'Apology',\n",
    " 'SetQ',\n",
    " 'PropQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(save_filename, dialogs, step_max=150000):\n",
    "    \n",
    "    graph_dict = defaultdict(int)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "\n",
    "        current_ind = 1\n",
    "        prev_row = None\n",
    "        row = None\n",
    "        for ind in range(len(thread)):\n",
    "            if prev_row:\n",
    "                row = thread[ind]\n",
    "\n",
    "            if not prev_row:\n",
    "                prev_row = thread[ind]\n",
    "                row = None\n",
    "\n",
    "            if row and current_ind < step_max:\n",
    "                prev_cluster_name = \"---\".join(reverse_index_f1[prev_row['cluster_id']])\n",
    "                cur_cluster_name = \"---\".join(reverse_index_f1[row['cluster_id']])\n",
    "                if prev_cluster_name == 'Undetected' or cur_cluster_name == 'Undetected':\n",
    "                    pass\n",
    "                else:\n",
    "                    edge = (prev_cluster_name, cur_cluster_name)\n",
    "                    graph_dict[edge] += 1\n",
    "                current_ind += 1\n",
    "                prev_row = row\n",
    "                row = None\n",
    "#     graph_dict = normalize_graph_dict(graph_dict)\n",
    "    G = nx.DiGraph()\n",
    "    weighted_edges = [(k[0], k[1], v) for k, v in graph_dict.items()]\n",
    "    G.add_weighted_edges_from(weighted_edges)\n",
    "\n",
    "    m = nx.adjacency_matrix(G).todense().astype(float)\n",
    "    m = np.squeeze(np.asarray(m))\n",
    "    m = np.log(m + 1)\n",
    "    m = m / np.linalg.norm(m)\n",
    "    nodes = list(G.nodes)\n",
    "    G = nx.from_numpy_matrix(m, create_using=nx.DiGraph)\n",
    "    mapping = dict(zip(range(len(nodes)), nodes))\n",
    "    G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "    for arr in m.tolist():\n",
    "        str_arr = [str(e) for e in arr]            \n",
    "    with open(save_filename, 'w') as f:        \n",
    "        print(\";\" + \";\".join(nodes1), file=f)\n",
    "        for node1 in nodes1:   \n",
    "            sim_arr = [node1]\n",
    "            for node2 in nodes2:\n",
    "                k = (node1, node2)\n",
    "                if k in G.edges:\n",
    "                    sim_arr.append(str(G.edges[k]['weight']))\n",
    "                else:\n",
    "                    sim_arr.append(str(0))\n",
    "            print(\";\".join(sim_arr), file=f)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_graph_path = f1_output_path + f'graph_{dataset_name}_{feature_name_1}_{n}.csv'\n",
    "graph = build_graph(csv_graph_path, f1_data['dialog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for node1 in nodes1:\n",
    "    sim_arr = []\n",
    "    for node2 in nodes2:\n",
    "        k = (node1, node2)\n",
    "        if k in graph.edges:\n",
    "            sim_arr.append(graph.edges[k]['weight'])\n",
    "        else:\n",
    "            sim_arr.append(None)\n",
    "    sims.append(sim_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "z = np.array(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "        z=z.T,\n",
    "        x=nodes1,\n",
    "        y=nodes2,\n",
    "        colorscale='Viridis'))\n",
    "fig.update_layout(\n",
    "    title=f\"Dialog act adjacency matrix scatterplot\",\n",
    "    xaxis_title=\" Nodes From\",\n",
    "    yaxis_title=\" Nodes To\",\n",
    ")\n",
    "fig.write_html(f1_output_path + f'{dataset_name}_{feature_name_1}_{n}_graph_scatter_plot.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X - cluster count in Multiwoz\n",
    "- Y - cluster count in TopicalChat\n",
    "- cluster_i = (X,Y) - one same cluster in MultiWoz and topicalchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_counts_in_dataset(dataset_name):\n",
    "    feature_name = 'dialog_tagger_features'\n",
    "    n = 1\n",
    "    f1_data_path = get_data_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "    f1_output_path = get_output_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "    f1_data = load_data(f1_data_path)\n",
    "    reverse_index_f1 = {i: c for c, i in sorted(f1_data['new_clusters'].items(), key=lambda x: x[1])} \n",
    "    cluster_counts = defaultdict(int)\n",
    "    for dialog_id, dialog in f1_data['dialog'].items():\n",
    "        thread = dialog['thread']\n",
    "        for row in thread:                \n",
    "            cluster_name = \"---\".join(reverse_index_f1[row['cluster_id']])\n",
    "            cluster_counts[cluster_name] += 1\n",
    "    return cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts_multiwoz = get_cluster_counts_in_dataset('multi-woz2')\n",
    "cluster_counts_topicalchat = get_cluster_counts_in_dataset('topicalchat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = nodes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys, texts = [], [], []\n",
    "for node in all_nodes:\n",
    "#     x = cluster_counts_multiwoz[node] / max(cluster_counts_multiwoz.values())\n",
    "#     y = cluster_counts_topicalchat[node] / max(cluster_counts_topicalchat.values())\n",
    "    x = np.log(cluster_counts_multiwoz[node])\n",
    "    y = np.log(cluster_counts_topicalchat[node])\n",
    "    text = node\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data=go.Scatter(x=xs,\n",
    "                                y=ys,\n",
    "                                mode='markers',\n",
    "                                text=texts,))\n",
    "\n",
    "fig.update_layout(title='Multiwoz and topicalchat data counts', \n",
    "                  xaxis_title=\" Multiwoz data count\",\n",
    "                  yaxis_title=\" Topicalchat data count\",)\n",
    "fig.write_html(f1_output_path + f'counts_comparison_{dataset_name}_{feature_name_1}_{n}_plot.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(graph, cluster_counts, prefix):\n",
    "    weighted_out_degree = graph.out_degree(weight='weight') \n",
    "    weighted_in_degree = graph.in_degree(weight='weight') \n",
    "    weighted_degree = graph.degree(weight='weight') \n",
    "    print(\"Node\", \"Count\", \"OutDeg\", \"InDeg\", \"Deg\", \"WeighOutDeg\", \"WeighInDeg\", \"WeighDeg\")        \n",
    "    for node, _ in sorted(graph.degree(weight='weight'), key=lambda x: x[1], reverse=True):    \n",
    "        print(f\"{prefix}_{node}\", cluster_counts[node], graph.out_degree[node], graph.in_degree[node], graph.degree[node], weighted_out_degree[node], weighted_in_degree[node], weighted_degree[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_normalized(graph):\n",
    "    in_degrees = graph.in_degree()\n",
    "    out_degrees = graph.out_degree()\n",
    "    degrees = graph.degree()\n",
    "    \n",
    "    out_degree_max = max(dict(out_degrees).values())\n",
    "    in_degree_max = max(dict(in_degrees).values())\n",
    "    degree_max = max(dict(degrees).values())\n",
    "    \n",
    "    weighted_out_degree = graph.out_degree(weight='weight') \n",
    "    weighted_in_degree = graph.in_degree(weight='weight') \n",
    "    weighted_degree = graph.degree(weight='weight') \n",
    "    \n",
    "    w_out_degree_max = max(dict(weighted_out_degree).values())\n",
    "    w_in_degree_max = max(dict(weighted_in_degree).values())\n",
    "    w_degree_max = max(dict(weighted_degree).values())\n",
    "    \n",
    "    print(\"Node\", \"OutDeg\", \"InDeg\", \"Deg\", \"WeighOutDeg\", \"WeighInDeg\", \"WeighDeg\")\n",
    "    for node in all_nodes:\n",
    "        print(node, out_degrees[node]/out_degree_max, in_degrees[node]/in_degree_max, degrees[node] / degree_max, \n",
    "                    weighted_out_degree[node] / w_out_degree_max, weighted_in_degree[node] / w_in_degree_max, weighted_degree[node] / w_degree_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'topicalchat'\n",
    "topical_data_path = get_data_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "topical_data = load_data(topical_data_path)\n",
    "\n",
    "csv_graph_path = '/tmp/' + f'graph_{dataset_name}_{feature_name_1}_{n}.csv'\n",
    "graph_topical = build_graph(csv_graph_path, topical_data['dialog'])\n",
    "\n",
    "dataset_name = 'multi-woz2'\n",
    "multiwoz_data_path = get_data_path(dataset_name, feature_name=feature_name_1, n=n)\n",
    "multiwoz_data = load_data(multiwoz_data_path)\n",
    "\n",
    "csv_graph_path = '/tmp/' + f'graph_{dataset_name}_{feature_name_1}_{n}.csv'\n",
    "graph_multiwoz = build_graph(csv_graph_path, multiwoz_data['dialog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f253d517650>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_topical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Count OutDeg InDeg Deg WeighOutDeg WeighInDeg WeighDeg\n",
      "TC_Statement 138531 11 11 22 1.6030474709459104 1.6312620551644925 3.234309526110403\n",
      "TC_Feedback 19883 11 10 21 1.1439962774506378 1.1546102552433706 2.2986065326940084\n",
      "TC_Undetected 12342 10 10 20 1.0771940988759996 1.1230417624749822 2.200235861350982\n",
      "TC_Directive 11682 10 10 20 1.102454348727868 1.097442641833719 2.1998969905615873\n",
      "TC_Thanking 2133 9 10 19 0.7620443166832148 0.846852042898295 1.6088963595815098\n",
      "TC_Salutation 2223 9 9 18 0.7946234263726227 0.7715268522247241 1.566150278597347\n",
      "TC_CheckQ 526 9 9 18 0.45599551934575916 0.5436089222575134 0.9996044416032726\n",
      "TC_Commissive 305 8 8 16 0.4438722067610031 0.4311781498955639 0.875050356656567\n",
      "TC_SetQ 223 8 7 15 0.46940767537286837 0.24032824251237994 0.7097359178852483\n",
      "TC_Apology 141 5 5 10 0.27060435674766525 0.27226690581788043 0.5428712625655456\n",
      "TC_PropQ 5 1 2 3 0.039010788643072426 0.05013265560370088 0.08914344424677331\n"
     ]
    }
   ],
   "source": [
    "print_table(graph_topical, cluster_counts_topicalchat, 'TC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Count OutDeg InDeg Deg WeighOutDeg WeighInDeg WeighDeg\n",
      "MW_Statement 85923 11 11 22 1.5523486305168581 1.5103553244930377 3.062703955009896\n",
      "MW_Directive 24321 10 10 20 1.228708473723932 1.2432442906813264 2.471952764405258\n",
      "MW_Thanking 16137 10 11 21 1.1963608059726218 1.1294023723415394 2.325763178314161\n",
      "MW_CheckQ 6779 10 10 20 0.9825125115216726 0.9627280044250204 1.945240515946693\n",
      "MW_Undetected 3095 11 9 20 0.8219991198594876 0.8219606365864054 1.643959756445893\n",
      "MW_Salutation 2908 10 9 19 0.7392901643641677 0.7368476860722901 1.4761378504364577\n",
      "MW_Feedback 1725 10 9 19 0.7421285326069114 0.7031488968072367 1.4452774294141482\n",
      "MW_Commissive 1280 10 10 20 0.6940766238252151 0.7024346286767051 1.39651125250192\n",
      "MW_Apology 331 10 10 20 0.45820064981258823 0.4824623983119287 0.940663048124517\n",
      "MW_SetQ 546 6 9 15 0.3803946458121342 0.5034359196200989 0.8838305654322332\n",
      "MW_PropQ 3 2 2 4 0.03579606919116487 0.03579606919116487 0.07159213838232974\n"
     ]
    }
   ],
   "source": [
    "print_table(graph_multiwoz, cluster_counts_multiwoz, 'MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement 85923\n",
      "Directive 24321\n",
      "Thanking 16137\n",
      "CheckQ 6779\n",
      "Undetected 3095\n",
      "Salutation 2908\n",
      "Feedback 1725\n",
      "Commissive 1280\n",
      "Apology 331\n",
      "SetQ 546\n",
      "PropQ 3\n",
      "\n",
      "Statement 138531\n",
      "Feedback 19883\n",
      "Undetected 12342\n",
      "Directive 11682\n",
      "Thanking 2133\n",
      "Salutation 2223\n",
      "CheckQ 526\n",
      "Commissive 305\n",
      "SetQ 223\n",
      "Apology 141\n",
      "PropQ 5\n"
     ]
    }
   ],
   "source": [
    "for node, _ in sorted(graph_multiwoz.degree(weight='weight'), key=lambda x: x[1], reverse=True):    \n",
    "    print(node, cluster_counts_multiwoz[node])\n",
    "print()\n",
    "for node, _ in sorted(graph_topical.degree(weight='weight'), key=lambda x: x[1], reverse=True):    \n",
    "    print(node, cluster_counts_topicalchat[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_places_in_dialogs(dialogs):\n",
    "    cluster_places = defaultdict(list)\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        for ind, row in enumerate(thread):               \n",
    "            cluster_name = \"---\".join(reverse_index_f1[row['cluster_id']])\n",
    "            if cluster_name == 'Undetected':\n",
    "                continue\n",
    "            if ind == 0:\n",
    "                cluster_places['start'].append(cluster_name)\n",
    "            elif ind == len(thread) - 1:\n",
    "                cluster_places['end'].append(cluster_name)\n",
    "            else:\n",
    "                cluster_places['in_between'].append(cluster_name)\n",
    "    return cluster_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_places = get_cluster_places_in_dialogs(topical_data['dialog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'Thanking': 219, 'Directive': 2142, 'Statement': 4805, 'Salutation': 1109, 'CheckQ': 52, 'SetQ': 154, 'Undetected': 82, 'Feedback': 54, 'Commissive': 3})\n"
     ]
    }
   ],
   "source": [
    "counts_dict = defaultdict(int)\n",
    "for e in cluster_places['start']:\n",
    "    counts_dict[e] += 1\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(dialogs, node_from, node_to):\n",
    "    examples = []\n",
    "    for dialog_id, dialog in dialogs.items():\n",
    "        thread = dialog['thread']\n",
    "        prev_row = None\n",
    "        for ind in range(len(thread)):\n",
    "            if prev_row:\n",
    "                row = thread[ind]\n",
    "\n",
    "            if not prev_row:\n",
    "                prev_row = thread[ind]\n",
    "                row = None\n",
    "\n",
    "            if row:\n",
    "                prev_cluster_name = \"---\".join(reverse_index_f1[prev_row['cluster_id']])\n",
    "                cur_cluster_name = \"---\".join(reverse_index_f1[row['cluster_id']])\n",
    "                if prev_cluster_name == 'Undetected' or cur_cluster_name == 'Undetected':\n",
    "                    pass\n",
    "                else:\n",
    "                    if node_from == prev_cluster_name and node_to == cur_cluster_name:\n",
    "                        examples.append((prev_row['text0'], row['text0']))                                            \n",
    "                prev_row = row\n",
    "                row = None\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did you know the first number the white house used was 1?',\n",
       "  'No didnt know about that theres a lot of interesting facts about the White House and presidents thanks for all the facts its been great chatting with you'),\n",
       " ('Hi! Do you like horses? Did you know Clint Eastwood has a mild horse allergy?',\n",
       "  'Hello,  yes love horses,  so beautiful.  Thats so interesting considering he was in all those western movies lol Did you know 95% of all modern thoroughbred racehorses can trace their y chromosome to one horse?')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = 'CheckQ'\n",
    "n2 = 'Thanking'\n",
    "# n1 = 'SetQ'\n",
    "# n2 = 'Directive'\n",
    "get_examples(topical_data['dialog'], n1, n2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('You are welcome.  Is there anything else I can assist you with today?',\n",
       "  'That is all. Thank you for your help! '),\n",
       " ('I was able to book you 6 tickets for that train. Your reference number is  PSQ9JOOI. Is there anything else I can help with? ',\n",
       "  'No, I do not think so. Thank you for your help. '),\n",
       " (\"Aylesbray postcode is cd17sr and Rosa's postcode is cb22ha. Is there anything else I can help you with today?\",\n",
       "  \"No thanks. That's all the help I need. Take care. Bye. \"),\n",
       " ('Okay, will that be all today or is there anything else I can help you with?',\n",
       "  'That is all. Thank you!'),\n",
       " (\"The address is king's parade, is there anything else I can do?\",\n",
       "  'No thank you. Thank you for your help.')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_examples(multiwoz_data['dialog'], n1, n2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "topical_chat= np.array([[1.638, 1.675],\n",
    "[1.152, 1.164],\n",
    "[1.122, 1.119],\n",
    "[0.760, 0.851],\n",
    "[0.808, 0.784],\n",
    "[0.442, 0.546],\n",
    "[0.436, 0.421],\n",
    "[0.476, 0.245],\n",
    "[0.247, 0.262],\n",
    "[0.045, 0.058]])\n",
    "\n",
    "multiwoz_arr = np.array([\n",
    "    [1.529, 1.488],\n",
    "[1.210,1.225],\n",
    "[1.155,1.115],\n",
    "[0.977,0.944],\n",
    "[0.710,0.720],\n",
    "[0.725,0.698],\n",
    "[0.694,0.697],\n",
    "[0.460,0.495],\n",
    "[0.414,0.505],\n",
    "[0.039,0.024]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4393693711832147\n",
      "0.3053289242132906\n",
      "0.2935249709576222\n",
      "0.22322587156830787\n",
      "0.20565109672097928\n",
      "0.14322129950211057\n",
      "0.11043254045858708\n",
      "0.06426596772530602\n",
      "0.06872523895522521\n",
      "0.015213984196194895\n"
     ]
    }
   ],
   "source": [
    "for e in topical_chat / np.linalg.norm(topical_chat):\n",
    "    print(e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37402117814673025\n",
      "0.30791394034257025\n",
      "0.28026452529140067\n",
      "0.23728225280276433\n",
      "0.1809779894258372\n",
      "0.17544810641560327\n",
      "0.1751967480969563\n",
      "0.12442236773026308\n",
      "0.12693595091673304\n",
      "0.006032599647527907\n"
     ]
    }
   ],
   "source": [
    "for e in multiwoz_arr / np.linalg.norm(multiwoz_arr):\n",
    "    print(e[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
